{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ==============================================\n",
    "# 1. å¯¼å…¥æ‰€éœ€åº“\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, classification_report,\n",
    "    confusion_matrix, roc_curve, auc\n",
    ")\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé¿å…å¯è§†åŒ–ä¸­æ–‡ä¹±ç ï¼‰\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # é»‘ä½“\n",
    "plt.rcParams['axes.unicode_minus'] = False    # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜\n",
    "\n",
    "# ==============================================\n",
    "# 2. æ•°æ®é¢„å¤„ç†\n",
    "# ==============================================\n",
    "# åŠ è½½æ•°æ®\n",
    "data =  pd.read_csv(r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\train.csv')\n",
    "\n",
    "# ç¼ºå¤±å€¼å¡«å……\n",
    "data['Age'] = data.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "data['Cabin'] = data['Cabin'].fillna('U').apply(lambda x: x[0])  # å¡«å……Uå¹¶æå–é¦–å­—æ¯\n",
    "\n",
    "# æ‹†åˆ†ç‰¹å¾Xå’Œæ ‡ç­¾y\n",
    "y = data['Survived']\n",
    "core_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin']\n",
    "X = data[core_features]\n",
    "\n",
    "# ç‰¹å¾ç¼–ç ï¼šç±»åˆ«ç‰¹å¾ç‹¬çƒ­ç¼–ç ï¼Œæ•°å€¼ç‰¹å¾ç›´æ¥ä¼ é€’\n",
    "categorical_features = ['Sex', 'Embarked', 'Cabin']\n",
    "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ==============================================\n",
    "# 3. æ„å»ºè½¯æŠ•ç¥¨èåˆæ¨¡å‹\n",
    "# ==============================================\n",
    "# å®šä¹‰åŸºæ¨¡å‹\n",
    "lr = LogisticRegression(random_state=42, max_iter=200)  # é€»è¾‘å›å½’\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)  # éšæœºæ£®æ—\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)  # XGBoost\n",
    "\n",
    "# è½¯æŠ•ç¥¨èåˆ\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lr), ('rf', rf), ('xgb', xgb)],\n",
    "    voting='soft',  # è½¯æŠ•ç¥¨ï¼šåŸºäºæ¦‚ç‡èåˆ\n",
    "    weights=[1, 1, 1]  # å„æ¨¡å‹æƒé‡\n",
    ")\n",
    "\n",
    "# å°è£…é¢„å¤„ç†+èåˆæ¨¡å‹çš„ç®¡é“\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting', voting_clf)\n",
    "])\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ==============================================\n",
    "# 4. æ¨¡å‹é¢„æµ‹ï¼ˆè·å–è¯„ä¼°æ‰€éœ€çš„é¢„æµ‹å€¼å’Œæ¦‚ç‡ï¼‰\n",
    "# ==============================================\n",
    "y_pred = model_pipeline.predict(X_test)  # é¢„æµ‹ç±»åˆ«ï¼ˆ0/1ï¼‰\n",
    "y_pred_proba = model_pipeline.predict_proba(X_test)  # é¢„æµ‹æ¦‚ç‡ï¼ˆ[:,0]æ˜¯æ­»äº¡æ¦‚ç‡ï¼Œ[:,1]æ˜¯ç”Ÿå­˜æ¦‚ç‡ï¼‰\n",
    "y_pred_proba_positive = y_pred_proba[:, 1]  # æ­£ç±»ï¼ˆç”Ÿå­˜=1ï¼‰çš„æ¦‚ç‡ï¼Œç”¨äºAUCå’ŒROC\n",
    "\n",
    "# ç›®æ ‡åç§°ï¼ˆå¯¹åº”0=æ­»äº¡ï¼Œ1=ç”Ÿå­˜ï¼‰\n",
    "target_names = ['æ­»äº¡', 'ç”Ÿå­˜']\n",
    "\n",
    "# ==============================================\n",
    "# 5. æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼ˆæ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ï¼‰\n",
    "# ==============================================\n",
    "print(\"ğŸ¯ æ¨¡å‹æ€§èƒ½è¯„ä¼°\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"å‡†ç¡®ç‡ (Accuracy): {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"AUC (ROCæ›²çº¿ä¸‹é¢ç§¯): {roc_auc_score(y_test, y_pred_proba_positive):.4f}\")\n",
    "print(\"\\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n"
   ],
   "id": "2286307dadfb820e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\test.csv')\n",
    "data['Age'] = data.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "data['Cabin'] = data['Cabin'].fillna('U').apply(lambda x: x[0])  # å¡«å……Uå¹¶æå–é¦–å­—æ¯\n"
   ],
   "id": "9c61d41f031c4f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.head()",
   "id": "21811b16f2b2455f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "core_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin']\n",
    "X = data[core_features]\n",
    "\n",
    "# ç‰¹å¾ç¼–ç ï¼šç±»åˆ«ç‰¹å¾ç‹¬çƒ­ç¼–ç ï¼Œæ•°å€¼ç‰¹å¾ç›´æ¥ä¼ é€’\n",
    "categorical_features = ['Sex', 'Embarked', 'Cabin']\n",
    "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ]\n",
    ")\n"
   ],
   "id": "663010c85a166089",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_pred = model_pipeline.predict(X)",
   "id": "334ab35fb23282b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ===================== 1. åŠ è½½è®­ç»ƒå¥½çš„èåˆæ¨¡å‹ =====================\n",
    "# æ›¿æ¢ä¸ºä½ æ¨¡å‹ä¿å­˜çš„å®é™…è·¯å¾„ï¼ˆä¹‹å‰ç”¨joblibä¿å­˜çš„titanic_voting_model.pklï¼‰\n",
    "model_path = \"titanic_voting_model.pkl\"\n",
    "loaded_model = joblib.load(model_path)\n",
    "print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\")\n",
    "\n",
    "# ===================== 2. è¯»å–æµ‹è¯•é›†æ•°æ® =====================\n",
    "# ä½ çš„test.csvè·¯å¾„\n",
    "test_data_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\test.csv'\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "# ä¿ç•™ä¹˜å®¢IDï¼ˆç”¨äºæœ€ç»ˆç»“æœæäº¤ï¼‰\n",
    "passenger_id = df_test['PassengerId']\n",
    "print(\"âœ… æµ‹è¯•é›†æ•°æ®è¯»å–å®Œæˆï¼Œå…±{}æ¡æ ·æœ¬\".format(len(df_test)))\n",
    "\n",
    "# ===================== 3. æ•°æ®é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰ =====================\n",
    "def preprocess_test_data(df):\n",
    "    # 1. å¡«å……Ageç¼ºå¤±å€¼ï¼šæŒ‰Pclass+Sexåˆ†ç»„å¡«å……ä¸­ä½æ•°\n",
    "    df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    # 2. å¡«å……Embarkedç¼ºå¤±å€¼ï¼šä¼—æ•°S\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    # 3. å¡«å……Fareç¼ºå¤±å€¼ï¼štest.csvç‰¹æœ‰ï¼ŒæŒ‰Pclassåˆ†ç»„å¡«å……ä¸­ä½æ•°\n",
    "    df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    # 4. å¤„ç†Cabinï¼šå¡«å……Uå¹¶æå–é¦–å­—æ¯\n",
    "    df['Cabin'] = df['Cabin'].fillna('U').apply(lambda x: x[0] if pd.notna(x) else 'U')\n",
    "    # 5. ç­›é€‰æ ¸å¿ƒç‰¹å¾ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰\n",
    "    core_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin']\n",
    "    return df[core_features]\n",
    "\n",
    "# æ‰§è¡Œé¢„å¤„ç†\n",
    "X_test = preprocess_test_data(df_test)\n",
    "print(\"âœ… æµ‹è¯•é›†æ•°æ®é¢„å¤„ç†å®Œæˆ\")\n",
    "\n",
    "# ===================== 4. æ¨¡å‹é¢„æµ‹ =====================\n",
    "# é¢„æµ‹ç”Ÿå­˜ç±»åˆ«ï¼ˆ0=æ­»äº¡ï¼Œ1=ç”Ÿå­˜ï¼‰\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "# å¯é€‰ï¼šé¢„æµ‹ç”Ÿå­˜æ¦‚ç‡\n",
    "y_pred_proba = loaded_model.predict_proba(X_test)[:, 1]  # ç”Ÿå­˜æ¦‚ç‡\n",
    "\n",
    "# ===================== 5. ç”Ÿæˆå¹¶ä¿å­˜é¢„æµ‹ç»“æœ =====================\n",
    "# æ„é€ ç»“æœDataFrame\n",
    "result = pd.DataFrame({\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': y_pred,\n",
    "    'Survived_Probability': y_pred_proba  # å¯é€‰ï¼šä¿å­˜ç”Ÿå­˜æ¦‚ç‡\n",
    "})\n",
    "\n",
    "# ä¿å­˜ç»“æœåˆ°CSVï¼ˆä¿å­˜åœ¨test.csvåŒç›®å½•ä¸‹ï¼‰\n",
    "result_save_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\predict_result.csv'\n",
    "result.to_csv(result_save_path, index=False)\n",
    "print(\"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ï¼š\", result_save_path)\n",
    "print(\"\\nğŸ“Œ å‰5æ¡é¢„æµ‹ç»“æœï¼š\")\n",
    "print(result.head())"
   ],
   "id": "de6c665fb24a8a12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ==============================================\n",
    "# 1. å¯¼å…¥æ‰€éœ€åº“ï¼ˆæ–°å¢joblibï¼Œç”¨äºæ¨¡å‹ä¿å­˜/åŠ è½½ï¼‰\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib  # æ–°å¢ï¼šæ¨¡å‹ä¿å­˜/åŠ è½½åº“\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, classification_report,\n",
    "    confusion_matrix, roc_curve, auc\n",
    ")\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé¿å…å¯è§†åŒ–ä¸­æ–‡ä¹±ç ï¼‰\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # é»‘ä½“\n",
    "plt.rcParams['axes.unicode_minus'] = False    # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜\n",
    "\n",
    "# ==============================================\n",
    "# 2. æ•°æ®é¢„å¤„ç†\n",
    "# ==============================================\n",
    "# åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰\n",
    "data =  pd.read_csv(r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\train.csv')\n",
    "\n",
    "# ç¼ºå¤±å€¼å¡«å……\n",
    "data['Age'] = data.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "data['Cabin'] = data['Cabin'].fillna('U').apply(lambda x: x[0])  # å¡«å……Uå¹¶æå–é¦–å­—æ¯\n",
    "\n",
    "# æ‹†åˆ†ç‰¹å¾Xå’Œæ ‡ç­¾y\n",
    "y = data['Survived']\n",
    "core_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin']\n",
    "X = data[core_features]\n",
    "\n",
    "# ç‰¹å¾ç¼–ç ï¼šç±»åˆ«ç‰¹å¾ç‹¬çƒ­ç¼–ç ï¼Œæ•°å€¼ç‰¹å¾ç›´æ¥ä¼ é€’\n",
    "categorical_features = ['Sex', 'Embarked', 'Cabin']\n",
    "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ==============================================\n",
    "# 3. æ„å»ºè½¯æŠ•ç¥¨èåˆæ¨¡å‹\n",
    "# ==============================================\n",
    "# å®šä¹‰åŸºæ¨¡å‹\n",
    "lr = LogisticRegression(random_state=42, max_iter=200)  # é€»è¾‘å›å½’\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)  # éšæœºæ£®æ—\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)  # XGBoost\n",
    "\n",
    "# è½¯æŠ•ç¥¨èåˆ\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lr), ('rf', rf), ('xgb', xgb)],\n",
    "    voting='soft',  # è½¯æŠ•ç¥¨ï¼šåŸºäºæ¦‚ç‡èåˆ\n",
    "    weights=[1, 1, 1]  # å„æ¨¡å‹æƒé‡\n",
    ")\n",
    "\n",
    "# å°è£…é¢„å¤„ç†+èåˆæ¨¡å‹çš„ç®¡é“\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting', voting_clf)\n",
    "])\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ==============================================\n",
    "# æ–°å¢ï¼šä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆå…³é”®æ­¥éª¤ï¼è§£å†³æ–‡ä»¶æ‰¾ä¸åˆ°çš„é—®é¢˜ï¼‰\n",
    "# ==============================================\n",
    "# æ¨¡å‹ä¿å­˜è·¯å¾„ï¼ˆå’Œtrain.csv/test.csvåŒç›®å½•ï¼Œé¿å…è·¯å¾„é”™è¯¯ï¼‰\n",
    "model_save_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\titanic_voting_model.pkl'\n",
    "joblib.dump(model_pipeline, model_save_path)\n",
    "print(f\"âœ… æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{model_save_path}\")\n",
    "\n",
    "# ==============================================\n",
    "# 4. æ¨¡å‹é¢„æµ‹ï¼ˆè·å–è¯„ä¼°æ‰€éœ€çš„é¢„æµ‹å€¼å’Œæ¦‚ç‡ï¼‰\n",
    "# ==============================================\n",
    "y_pred = model_pipeline.predict(X_test)  # é¢„æµ‹ç±»åˆ«ï¼ˆ0/1ï¼‰\n",
    "y_pred_proba = model_pipeline.predict_proba(X_test)  # é¢„æµ‹æ¦‚ç‡ï¼ˆ[:,0]æ˜¯æ­»äº¡æ¦‚ç‡ï¼Œ[:,1]æ˜¯ç”Ÿå­˜æ¦‚ç‡ï¼‰\n",
    "y_pred_proba_positive = y_pred_proba[:, 1]  # æ­£ç±»ï¼ˆç”Ÿå­˜=1ï¼‰çš„æ¦‚ç‡ï¼Œç”¨äºAUCå’ŒROC\n",
    "\n",
    "# ç›®æ ‡åç§°ï¼ˆå¯¹åº”0=æ­»äº¡ï¼Œ1=ç”Ÿå­˜ï¼‰\n",
    "target_names = ['æ­»äº¡', 'ç”Ÿå­˜']\n",
    "\n",
    "# ==============================================\n",
    "# 5. æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼ˆæ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ï¼‰\n",
    "# ==============================================\n",
    "print(\"ğŸ¯ æ¨¡å‹æ€§èƒ½è¯„ä¼°\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"å‡†ç¡®ç‡ (Accuracy): {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"AUC (ROCæ›²çº¿ä¸‹é¢ç§¯): {roc_auc_score(y_test, y_pred_proba_positive):.4f}\")\n",
    "print(\"\\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# ==============================================\n",
    "# 6. å¯è§†åŒ–ï¼šæ··æ·†çŸ©é˜µ + ROC æ›²çº¿\n",
    "# ==============================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- æ··æ·†çŸ©é˜µå¯è§†åŒ– ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=target_names,\n",
    "    yticklabels=target_names,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('æ··æ·†çŸ©é˜µ', fontsize=12)\n",
    "axes[0].set_ylabel('çœŸå®æ ‡ç­¾', fontsize=10)\n",
    "axes[0].set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=10)\n",
    "\n",
    "# --- ROCæ›²çº¿å¯è§†åŒ– ---\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_positive)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--', label='éšæœºåˆ†ç±»å™¨')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('å‡æ­£ç‡ (False Positive Rate)', fontsize=10)\n",
    "axes[1].set_ylabel('çœŸæ­£ç‡ (True Positive Rate)', fontsize=10)\n",
    "axes[1].set_title('ROC æ›²çº¿', fontsize=12)\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==============================================\n",
    "# 7. ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆé€»è¾‘å›å½’ç³»æ•° + éšæœºæ£®æ—/XGBoostç‰¹å¾é‡è¦æ€§ï¼‰\n",
    "# ==============================================\n",
    "# å…³é”®æ­¥éª¤ï¼šæå–é¢„å¤„ç†åçš„**å®Œæ•´ç‰¹å¾åç§°**ï¼ˆç‹¬çƒ­ç¼–ç +æ•°å€¼ç‰¹å¾ï¼‰\n",
    "# 1) è·å–ç‹¬çƒ­ç¼–ç çš„ç‰¹å¾å\n",
    "cat_encoder = model_pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "cat_feature_names = cat_encoder.get_feature_names_out(categorical_features)\n",
    "# 2) åˆå¹¶æ•°å€¼ç‰¹å¾åï¼Œå¾—åˆ°å®Œæ•´ç‰¹å¾åˆ—è¡¨\n",
    "feature_names = list(cat_feature_names) + numerical_features\n",
    "\n",
    "# --- é€»è¾‘å›å½’ç³»æ•°åˆ†æï¼ˆèåˆæ¨¡å‹ä¸­æå–LRæ¨¡å‹ï¼‰---\n",
    "# ä»Pipelineä¸­æå–è½¯æŠ•ç¥¨æ¨¡å‹ï¼Œå†æå–é€»è¾‘å›å½’å®ä¾‹\n",
    "lr_model = model_pipeline.named_steps['voting'].estimators_[0]\n",
    "lr_coef = lr_model.coef_[0]  # é€»è¾‘å›å½’çš„ç‰¹å¾ç³»æ•°\n",
    "\n",
    "# æ„å»ºç‰¹å¾é‡è¦æ€§DataFrame\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': lr_coef,\n",
    "    'Abs_Coefficient': np.abs(lr_coef)\n",
    "}).sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ” å‰10ä¸ªæœ€é‡è¦çš„ç‰¹å¾ï¼ˆé€»è¾‘å›å½’ç³»æ•°ç»å¯¹å€¼æ’åºï¼‰:\")\n",
    "print(feature_importance_df[['Feature', 'Coefficient']].head(10).to_string(index=False))\n",
    "\n",
    "# --- å¯è§†åŒ–é€»è¾‘å›å½’å‰10é‡è¦ç‰¹å¾ ---\n",
    "top_n = 10\n",
    "top_features = feature_importance_df.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# é¢œè‰²ï¼šç³»æ•°ä¸ºè´Ÿâ†’çº¢è‰²ï¼ˆå¢å¤§è¯¥ç‰¹å¾â†’æ›´å¯èƒ½æ­»äº¡ï¼‰ï¼Œç³»æ•°ä¸ºæ­£â†’ç»¿è‰²ï¼ˆå¢å¤§è¯¥ç‰¹å¾â†’æ›´å¯èƒ½ç”Ÿå­˜ï¼‰\n",
    "colors = ['red' if c < 0 else 'green' for c in top_features['Coefficient']]\n",
    "plt.barh(range(top_n), top_features['Coefficient'], color=colors)\n",
    "plt.yticks(range(top_n), top_features['Feature'])\n",
    "plt.xlabel('é€»è¾‘å›å½’ç³»æ•°', fontsize=10)\n",
    "plt.title(f'å‰ {top_n} ä¸ªæœ€é‡è¦ç‰¹å¾çš„æƒé‡\\nï¼ˆçº¢è‰²ï¼šå¢å¤§ç‰¹å¾â†’æ›´å¯èƒ½æ­»äº¡ï¼›ç»¿è‰²ï¼šå¢å¤§ç‰¹å¾â†’æ›´å¯èƒ½ç”Ÿå­˜ï¼‰', fontsize=12)\n",
    "plt.gca().invert_yaxis()  # æœ€é‡è¦çš„ç‰¹å¾åœ¨é¡¶éƒ¨\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- è¡¥å……ï¼šéšæœºæ£®æ—å’ŒXGBoostçš„ç‰¹å¾é‡è¦æ€§ï¼ˆå¯é€‰ï¼‰---\n",
    "print(\"\\nğŸ“Œ éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§å‰10:\")\n",
    "rf_model = model_pipeline.named_steps['voting'].estimators_[1]\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False).head(10)\n",
    "print(rf_importance.to_string(index=False))\n",
    "\n",
    "print(\"\\nğŸ“Œ XGBoostç‰¹å¾é‡è¦æ€§å‰10:\")\n",
    "xgb_model = model_pipeline.named_steps['voting'].estimators_[2]\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False).head(10)\n",
    "print(xgb_importance.to_string(index=False))\n",
    "\n",
    "# ==============================================\n",
    "# 8. åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹test.csvæ•°æ®\n",
    "# ==============================================\n",
    "# åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨å’Œä¿å­˜æ—¶ç›¸åŒçš„è·¯å¾„ï¼Œé¿å…æ‰¾ä¸åˆ°æ–‡ä»¶ï¼‰\n",
    "model_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\titanic_voting_model.pkl'\n",
    "loaded_model = joblib.load(model_path)\n",
    "print(f\"\\nâœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼š{model_path}\")\n",
    "\n",
    "# è¯»å–æµ‹è¯•é›†æ•°æ®\n",
    "test_data_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\test.csv'\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "passenger_id = df_test['PassengerId']\n",
    "print(f\"âœ… æµ‹è¯•é›†æ•°æ®è¯»å–å®Œæˆï¼Œå…±{len(df_test)}æ¡æ ·æœ¬\")\n",
    "\n",
    "# æµ‹è¯•é›†æ•°æ®é¢„å¤„ç†å‡½æ•°\n",
    "def preprocess_test_data(df):\n",
    "    # 1. å¡«å……Ageç¼ºå¤±å€¼ï¼šæŒ‰Pclass+Sexåˆ†ç»„å¡«å……ä¸­ä½æ•°\n",
    "    df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    # 2. å¡«å……Embarkedç¼ºå¤±å€¼ï¼šä¼—æ•°S\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    # 3. å¡«å……Fareç¼ºå¤±å€¼ï¼štest.csvç‰¹æœ‰ï¼ŒæŒ‰Pclassåˆ†ç»„å¡«å……ä¸­ä½æ•°\n",
    "    df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    # 4. å¤„ç†Cabinï¼šå¡«å……Uå¹¶æå–é¦–å­—æ¯\n",
    "    df['Cabin'] = df['Cabin'].fillna('U').apply(lambda x: x[0] if pd.notna(x) else 'U')\n",
    "    # 5. ç­›é€‰æ ¸å¿ƒç‰¹å¾\n",
    "    core_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin']\n",
    "    return df[core_features]\n",
    "\n",
    "# æ‰§è¡Œé¢„å¤„ç†\n",
    "X_test = preprocess_test_data(df_test)\n",
    "print(\"âœ… æµ‹è¯•é›†æ•°æ®é¢„å¤„ç†å®Œæˆ\")\n",
    "\n",
    "# æ¨¡å‹é¢„æµ‹\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_proba = loaded_model.predict_proba(X_test)[:, 1]  # ç”Ÿå­˜æ¦‚ç‡\n",
    "\n",
    "# ç”Ÿæˆå¹¶ä¿å­˜é¢„æµ‹ç»“æœ\n",
    "result = pd.DataFrame({\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': y_pred,\n",
    "    'Survived_Probability': y_pred_proba\n",
    "})\n",
    "result_save_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\predict_result.csv'\n",
    "result.to_csv(result_save_path, index=False)\n",
    "print(f\"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ï¼š{result_save_path}\")\n",
    "print(\"\\nğŸ“Œ å‰5æ¡é¢„æµ‹ç»“æœï¼š\")\n",
    "print(result.head())"
   ],
   "id": "5d995a33e290491f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ==============================================\n",
    "# 1. å¯¼å…¥æ‰©å±•åº“ï¼ˆæ–°å¢LightGBMã€ç½‘æ ¼æœç´¢ã€æ­£åˆ™åŒ–ç­‰ï¼‰\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import re  # ç”¨äºæå–å§“åä¸­çš„å¤´è¡”\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ==============================================\n",
    "# 2. å¢å¼ºç‰ˆç‰¹å¾å·¥ç¨‹ï¼ˆæ ¸å¿ƒä¼˜åŒ–ç‚¹ï¼‰\n",
    "# ==============================================\n",
    "def load_and_engineer_data(train_path, test_path=None):\n",
    "    \"\"\"åŠ è½½æ•°æ®å¹¶æ‰§è¡Œç‰¹å¾å·¥ç¨‹ï¼Œè¿”å›å¤„ç†åçš„è®­ç»ƒ/æµ‹è¯•æ•°æ®\"\"\"\n",
    "    # åŠ è½½è®­ç»ƒé›†\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df = df_train.copy()\n",
    "    test_flag = False\n",
    "    if test_path:\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        df_test['Survived'] = -1  # æ ‡è®°æµ‹è¯•é›†æ ‡ç­¾\n",
    "        df = pd.concat([df, df_test], ignore_index=True)\n",
    "        test_flag = True\n",
    "\n",
    "    # -------- ç¼ºå¤±å€¼å¡«å……ï¼ˆç²¾ç»†åŒ–ï¼‰ --------\n",
    "    # å¹´é¾„ï¼šæŒ‰å¤´è¡”+èˆ±ä½åˆ†ç»„å¡«å……ï¼ˆæ¯”ä»…Pclass+Sexæ›´ç²¾å‡†ï¼‰\n",
    "    df['Title'] = df['Name'].apply(lambda x: re.findall(r'([A-Za-z]+)\\.', x)[0])  # æå–å¤´è¡”\n",
    "    df['Age'] = df.groupby(['Pclass', 'Title'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    # ç™»èˆ¹æ¸¯å£ï¼šä¼—æ•°å¡«å……\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    # ç¥¨ä»·ï¼šæŒ‰èˆ±ä½åˆ†ç»„å¡«å……\n",
    "    df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    # èˆ±ä½ï¼šå¡«å……Uå¹¶æå–é¦–å­—æ¯ï¼Œåˆå¹¶ç¨€æœ‰èˆ±ä½\n",
    "    df['Cabin'] = df['Cabin'].fillna('U').apply(lambda x: x[0] if pd.notna(x) else 'U')\n",
    "    rare_cabins = df['Cabin'].value_counts()[df['Cabin'].value_counts() < 10].index\n",
    "    df['Cabin'] = df['Cabin'].replace(rare_cabins, 'R')  # ç¨€æœ‰èˆ±ä½åˆå¹¶ä¸ºR\n",
    "\n",
    "    # -------- è¡ç”Ÿç‰¹å¾ï¼ˆæ ¸å¿ƒï¼ï¼‰ --------\n",
    "    # 1. å®¶åº­è§„æ¨¡ï¼šå…„å¼Ÿå§å¦¹+çˆ¶æ¯å­å¥³+è‡ªå·±\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    # 2. æ˜¯å¦å•èº«\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    # 3. å¤´è¡”åˆå¹¶ï¼ˆå‡å°‘ç±»åˆ«æ•°ï¼‰\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Don': 'Noble', 'Sir': 'Noble', 'Lady': 'Noble', 'Countess': 'Noble', 'Dona': 'Noble',\n",
    "        'Dr': 'Professional', 'Rev': 'Professional', 'Col': 'Military', 'Major': 'Military', 'Capt': 'Military',\n",
    "        'Ms': 'Miss', 'Mlle': 'Miss', 'Mme': 'Mrs'\n",
    "    }\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "    # 4. ç¥¨ä»·åˆ†ç®±ï¼ˆæ•æ‰éçº¿æ€§å…³ç³»ï¼‰\n",
    "    df['FareBin'] = pd.cut(df['Fare'], bins=[0, 10, 30, 100, 600], labels=['Low', 'Mid', 'High', 'Luxury'])\n",
    "    # 5. å¹´é¾„åˆ†ç®±\n",
    "    df['AgeBin'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], labels=['Child', 'Teen', 'Adult', 'Middle', 'Elder'])\n",
    "\n",
    "    # -------- ç­›é€‰ç‰¹å¾ --------\n",
    "    # æœ€ç»ˆç‰¹å¾åˆ—è¡¨ï¼ˆå«è¡ç”Ÿç‰¹å¾ï¼‰\n",
    "    core_features = [\n",
    "        'Pclass', 'Sex', 'Embarked', 'Cabin', 'Title',\n",
    "        'FamilySize', 'IsAlone', 'FareBin', 'AgeBin'\n",
    "    ]\n",
    "    target = 'Survived'\n",
    "\n",
    "    # æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›†\n",
    "    if test_flag:\n",
    "        df_train_processed = df[df[target] != -1].copy()\n",
    "        df_test_processed = df[df[target] == -1].copy()\n",
    "        X_train = df_train_processed[core_features]\n",
    "        y_train = df_train_processed[target]\n",
    "        X_test = df_test_processed[core_features]\n",
    "        passenger_id = df_test_processed['PassengerId']\n",
    "        return X_train, y_train, X_test, passenger_id\n",
    "    else:\n",
    "        X = df[core_features]\n",
    "        y = df[target]\n",
    "        return X, y\n",
    "\n",
    "# åŠ è½½æ•°æ®å¹¶æ‰§è¡Œç‰¹å¾å·¥ç¨‹ï¼ˆä¿®æ”¹ä¸ºä½ çš„è·¯å¾„ï¼‰\n",
    "train_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\train.csv'\n",
    "test_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\test.csv'\n",
    "X, y, X_test, passenger_id = load_and_engineer_data(train_path, test_path)\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆæ¯”åŸä»£ç çš„train_test_splitæ›´åˆç†ï¼‰\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ==============================================\n",
    "# 3. é¢„å¤„ç†ç®¡é“ï¼ˆé€‚é…æ–°ç‰¹å¾ï¼‰\n",
    "# ==============================================\n",
    "# å®šä¹‰ç±»åˆ«ç‰¹å¾ï¼ˆæ‰€æœ‰éæ•°å€¼ç‰¹å¾ï¼‰\n",
    "categorical_features = X_train.columns.tolist()  # ç»ç‰¹å¾å·¥ç¨‹åå‡ä¸ºç±»åˆ«ç‰¹å¾\n",
    "# é¢„å¤„ç†ï¼šç‹¬çƒ­ç¼–ç ï¼ˆå¿½ç•¥æœªçŸ¥ç±»åˆ«ï¼‰\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ==============================================\n",
    "# 4. æ¨¡å‹è¶…å‚æ•°è°ƒä¼˜ï¼ˆGridSearchCVï¼‰\n",
    "# ==============================================\n",
    "def tune_model(model, param_grid, X, y):\n",
    "    \"\"\"ç½‘æ ¼æœç´¢è°ƒå‚ï¼Œè¿”å›æœ€ä¼˜æ¨¡å‹\"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,  # 5æŠ˜äº¤å‰éªŒè¯\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # å¹¶è¡Œè®¡ç®—\n",
    "        verbose=0\n",
    "    )\n",
    "    grid_search.fit(preprocessor.fit_transform(X), y)\n",
    "    print(f\"âœ… {model.__class__.__name__} æœ€ä¼˜å‚æ•°ï¼š{grid_search.best_params_}\")\n",
    "    print(f\"âœ… äº¤å‰éªŒè¯æœ€ä¼˜å‡†ç¡®ç‡ï¼š{grid_search.best_score_:.4f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# -------- å®šä¹‰åŸºæ¨¡å‹åŠè°ƒå‚ç½‘æ ¼ --------\n",
    "# XGBoostè°ƒå‚\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_param = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "best_xgb = tune_model(xgb, xgb_param, X_train, y_train)\n",
    "\n",
    "# LightGBMè°ƒå‚ï¼ˆæ–°å¢é«˜æ•ˆæ¨¡å‹ï¼‰\n",
    "lgb = LGBMClassifier(random_state=42, verbose=-1)\n",
    "lgb_param = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 63]\n",
    "}\n",
    "best_lgb = tune_model(lgb, lgb_param, X_train, y_train)\n",
    "\n",
    "# éšæœºæ£®æ—è°ƒå‚\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 8],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "best_rf = tune_model(rf, rf_param, X_train, y_train)\n",
    "\n",
    "# ==============================================\n",
    "# 5. å †å é›†æˆæ¨¡å‹ï¼ˆStackingï¼‰\n",
    "# ==============================================\n",
    "# å®šä¹‰åŸºæ¨¡å‹åˆ—è¡¨\n",
    "base_models = [\n",
    "    ('xgb', best_xgb),\n",
    "    ('lgb', best_lgb),\n",
    "    ('rf', best_rf),\n",
    "    ('svc', SVC(probability=True, random_state=42)),  # SVMï¼ˆå¸¦æ¦‚ç‡ï¼‰\n",
    "    ('ridge', RidgeClassifier(random_state=42))       # å²­å›å½’\n",
    "]\n",
    "\n",
    "# å †å é›†æˆï¼šäºŒçº§æ¨¡å‹ç”¨é€»è¾‘å›å½’\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=500),\n",
    "    cv=5,  # 5æŠ˜äº¤å‰éªŒè¯ç”ŸæˆåŸºæ¨¡å‹çš„é¢„æµ‹\n",
    "    stack_method='predict_proba'  # ç”¨æ¦‚ç‡ä½œä¸ºäºŒçº§ç‰¹å¾\n",
    ")\n",
    "\n",
    "# å°è£…é¢„å¤„ç†+å †å æ¨¡å‹çš„ç®¡é“\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', stacking_clf)\n",
    "])\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ==============================================\n",
    "# 6. æ¨¡å‹è¯„ä¼°ï¼ˆå‡†ç¡®ç‡å¤§å¹…æå‡ï¼‰\n",
    "# ==============================================\n",
    "# éªŒè¯é›†é¢„æµ‹\n",
    "y_pred = model_pipeline.predict(X_val)\n",
    "y_pred_proba = model_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# è¾“å‡ºè¯„ä¼°æŒ‡æ ‡\n",
    "print(\"\\nğŸ¯ ä¼˜åŒ–åæ¨¡å‹æ€§èƒ½è¯„ä¼°\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"éªŒè¯é›†å‡†ç¡®ç‡: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(f\"éªŒè¯é›†AUC: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "print(\"\\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_val, y_pred, target_names=['æ­»äº¡', 'ç”Ÿå­˜']))\n",
    "\n",
    "# æ··æ·†çŸ©é˜µ+ROCæ›²çº¿å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['æ­»äº¡', 'ç”Ÿå­˜'], yticklabels=['æ­»äº¡', 'ç”Ÿå­˜'], ax=axes[0])\n",
    "axes[0].set_title('æ··æ·†çŸ©é˜µ', fontsize=12)\n",
    "axes[0].set_ylabel('çœŸå®æ ‡ç­¾')\n",
    "axes[0].set_xlabel('é¢„æµ‹æ ‡ç­¾')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "axes[1].set_xlabel('å‡æ­£ç‡')\n",
    "axes[1].set_ylabel('çœŸæ­£ç‡')\n",
    "axes[1].set_title('ROCæ›²çº¿')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==============================================\n",
    "# 7. ä¿å­˜æ¨¡å‹+é¢„æµ‹æµ‹è¯•é›†\n",
    "# ==============================================\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "model_save_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\titanic_stacking_model.pkl'\n",
    "joblib.dump(model_pipeline, model_save_path)\n",
    "print(f\"\\nâœ… æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{model_save_path}\")\n",
    "\n",
    "# æµ‹è¯•é›†é¢„æµ‹\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "y_test_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ç”Ÿæˆé¢„æµ‹ç»“æœ\n",
    "result = pd.DataFrame({\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': y_test_pred.astype(int),\n",
    "    'Survived_Probability': y_test_proba\n",
    "})\n",
    "result_save_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\optimized_predict_result.csv'\n",
    "result.to_csv(result_save_path, index=False)\n",
    "print(f\"âœ… ä¼˜åŒ–åé¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ï¼š{result_save_path}\")\n",
    "print(\"\\nğŸ“Œ æµ‹è¯•é›†å‰5æ¡é¢„æµ‹ç»“æœï¼š\")\n",
    "print(result.head())"
   ],
   "id": "9a01ed6e7a9dbf77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ==============================================\n",
    "# 1. å¯¼å…¥æ‰©å±•åº“ï¼ˆæ–°å¢LightGBMã€ç½‘æ ¼æœç´¢ã€æ­£åˆ™åŒ–ç­‰ï¼‰\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression  # ä¿ç•™é€»è¾‘å›å½’ï¼Œåˆ é™¤RidgeClassifierå¼•ç”¨\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import re  # ç”¨äºæå–å§“åä¸­çš„å¤´è¡”\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ==============================================\n",
    "# 2. å¢å¼ºç‰ˆç‰¹å¾å·¥ç¨‹ï¼ˆæ ¸å¿ƒä¼˜åŒ–ç‚¹ï¼‰\n",
    "# ==============================================\n",
    "def load_and_engineer_data(train_path, test_path=None):\n",
    "    \"\"\"åŠ è½½æ•°æ®å¹¶æ‰§è¡Œç‰¹å¾å·¥ç¨‹ï¼Œè¿”å›å¤„ç†åçš„è®­ç»ƒ/æµ‹è¯•æ•°æ®\"\"\"\n",
    "    # åŠ è½½è®­ç»ƒé›†\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df = df_train.copy()\n",
    "    test_flag = False\n",
    "    if test_path:\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        df_test['Survived'] = -1  # æ ‡è®°æµ‹è¯•é›†æ ‡ç­¾\n",
    "        df = pd.concat([df, df_test], ignore_index=True)\n",
    "        test_flag = True\n",
    "\n",
    "    # -------- ç¼ºå¤±å€¼å¡«å……ï¼ˆç²¾ç»†åŒ–ï¼‰ --------\n",
    "    # å¹´é¾„ï¼šæŒ‰å¤´è¡”+èˆ±ä½åˆ†ç»„å¡«å……ï¼ˆæ¯”ä»…Pclass+Sexæ›´ç²¾å‡†ï¼‰\n",
    "    df['Title'] = df['Name'].apply(lambda x: re.findall(r'([A-Za-z]+)\\.', x)[0])  # æå–å¤´è¡”\n",
    "    df['Age'] = df.groupby(['Pclass', 'Title'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    # ç™»èˆ¹æ¸¯å£ï¼šä¼—æ•°å¡«å……\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    # ç¥¨ä»·ï¼šæŒ‰èˆ±ä½åˆ†ç»„å¡«å……\n",
    "    df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    # èˆ±ä½ï¼šå¡«å……Uå¹¶æå–é¦–å­—æ¯ï¼Œåˆå¹¶ç¨€æœ‰èˆ±ä½\n",
    "    df['Cabin'] = df['Cabin'].fillna('U').apply(lambda x: x[0] if pd.notna(x) else 'U')\n",
    "    rare_cabins = df['Cabin'].value_counts()[df['Cabin'].value_counts() < 10].index\n",
    "    df['Cabin'] = df['Cabin'].replace(rare_cabins, 'R')  # ç¨€æœ‰èˆ±ä½åˆå¹¶ä¸ºR\n",
    "\n",
    "    # -------- è¡ç”Ÿç‰¹å¾ï¼ˆæ ¸å¿ƒï¼ï¼‰ --------\n",
    "    # 1. å®¶åº­è§„æ¨¡ï¼šå…„å¼Ÿå§å¦¹+çˆ¶æ¯å­å¥³+è‡ªå·±\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    # 2. æ˜¯å¦å•èº«\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    # 3. å¤´è¡”åˆå¹¶ï¼ˆå‡å°‘ç±»åˆ«æ•°ï¼‰\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Don': 'Noble', 'Sir': 'Noble', 'Lady': 'Noble', 'Countess': 'Noble', 'Dona': 'Noble',\n",
    "        'Dr': 'Professional', 'Rev': 'Professional', 'Col': 'Military', 'Major': 'Military', 'Capt': 'Military',\n",
    "        'Ms': 'Miss', 'Mlle': 'Miss', 'Mme': 'Mrs'\n",
    "    }\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "    # 4. ç¥¨ä»·åˆ†ç®±ï¼ˆæ•æ‰éçº¿æ€§å…³ç³»ï¼‰\n",
    "    df['FareBin'] = pd.cut(df['Fare'], bins=[0, 10, 30, 100, 600], labels=['Low', 'Mid', 'High', 'Luxury'])\n",
    "    # 5. å¹´é¾„åˆ†ç®±\n",
    "    df['AgeBin'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], labels=['Child', 'Teen', 'Adult', 'Middle', 'Elder'])\n",
    "\n",
    "    # -------- ç­›é€‰ç‰¹å¾ --------\n",
    "    # æœ€ç»ˆç‰¹å¾åˆ—è¡¨ï¼ˆå«è¡ç”Ÿç‰¹å¾ï¼‰\n",
    "    core_features = [\n",
    "        'Pclass', 'Sex', 'Embarked', 'Cabin', 'Title',\n",
    "        'FamilySize', 'IsAlone', 'FareBin', 'AgeBin'\n",
    "    ]\n",
    "    target = 'Survived'\n",
    "\n",
    "    # æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›†\n",
    "    if test_flag:\n",
    "        df_train_processed = df[df[target] != -1].copy()\n",
    "        df_test_processed = df[df[target] == -1].copy()\n",
    "        X_train = df_train_processed[core_features]\n",
    "        y_train = df_train_processed[target]\n",
    "        X_test = df_test_processed[core_features]\n",
    "        passenger_id = df_test_processed['PassengerId']\n",
    "        return X_train, y_train, X_test, passenger_id\n",
    "    else:\n",
    "        X = df[core_features]\n",
    "        y = df[target]\n",
    "        return X, y\n",
    "\n",
    "# åŠ è½½æ•°æ®å¹¶æ‰§è¡Œç‰¹å¾å·¥ç¨‹ï¼ˆä¿®æ”¹ä¸ºä½ çš„è·¯å¾„ï¼‰\n",
    "train_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\train.csv'\n",
    "test_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\test.csv'\n",
    "X, y, X_test, passenger_id = load_and_engineer_data(train_path, test_path)\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆæ¯”åŸä»£ç çš„train_test_splitæ›´åˆç†ï¼‰\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ==============================================\n",
    "# 3. é¢„å¤„ç†ç®¡é“ï¼ˆé€‚é…æ–°ç‰¹å¾ï¼‰\n",
    "# ==============================================\n",
    "# å®šä¹‰ç±»åˆ«ç‰¹å¾ï¼ˆæ‰€æœ‰éæ•°å€¼ç‰¹å¾ï¼‰\n",
    "categorical_features = X_train.columns.tolist()  # ç»ç‰¹å¾å·¥ç¨‹åå‡ä¸ºç±»åˆ«ç‰¹å¾\n",
    "# é¢„å¤„ç†ï¼šç‹¬çƒ­ç¼–ç ï¼ˆå¿½ç•¥æœªçŸ¥ç±»åˆ«ï¼‰\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ==============================================\n",
    "# 4. æ¨¡å‹è¶…å‚æ•°è°ƒä¼˜ï¼ˆGridSearchCVï¼‰\n",
    "# ==============================================\n",
    "def tune_model(model, param_grid, X, y):\n",
    "    \"\"\"ç½‘æ ¼æœç´¢è°ƒå‚ï¼Œè¿”å›æœ€ä¼˜æ¨¡å‹\"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,  # 5æŠ˜äº¤å‰éªŒè¯\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # å¹¶è¡Œè®¡ç®—\n",
    "        verbose=0\n",
    "    )\n",
    "    grid_search.fit(preprocessor.fit_transform(X), y)\n",
    "    print(f\"âœ… {model.__class__.__name__} æœ€ä¼˜å‚æ•°ï¼š{grid_search.best_params_}\")\n",
    "    print(f\"âœ… äº¤å‰éªŒè¯æœ€ä¼˜å‡†ç¡®ç‡ï¼š{grid_search.best_score_:.4f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# -------- å®šä¹‰åŸºæ¨¡å‹åŠè°ƒå‚ç½‘æ ¼ --------\n",
    "# XGBoostè°ƒå‚\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_param = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "best_xgb = tune_model(xgb, xgb_param, X_train, y_train)\n",
    "\n",
    "# LightGBMè°ƒå‚ï¼ˆæ–°å¢é«˜æ•ˆæ¨¡å‹ï¼‰\n",
    "lgb = LGBMClassifier(random_state=42, verbose=-1)\n",
    "lgb_param = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 63]\n",
    "}\n",
    "best_lgb = tune_model(lgb, lgb_param, X_train, y_train)\n",
    "\n",
    "# éšæœºæ£®æ—è°ƒå‚\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 8],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "best_rf = tune_model(rf, rf_param, X_train, y_train)\n",
    "\n",
    "# ==============================================\n",
    "# 5. å †å é›†æˆæ¨¡å‹ï¼ˆStackingï¼‰- ä¿®å¤æ ¸å¿ƒé”™è¯¯\n",
    "# ==============================================\n",
    "# å®šä¹‰åŸºæ¨¡å‹åˆ—è¡¨ï¼ˆæ›¿æ¢RidgeClassifierä¸ºLogisticRegressionï¼‰\n",
    "base_models = [\n",
    "    ('xgb', best_xgb),\n",
    "    ('lgb', best_lgb),\n",
    "    ('rf', best_rf),\n",
    "    ('svc', SVC(probability=True, random_state=42)),  # SVMï¼ˆå¸¦æ¦‚ç‡ï¼‰\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=500))  # æ–°å¢é€»è¾‘å›å½’ä½œä¸ºåŸºæ¨¡å‹\n",
    "]\n",
    "\n",
    "# å †å é›†æˆï¼šäºŒçº§æ¨¡å‹ç”¨é€»è¾‘å›å½’\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=500),\n",
    "    cv=5,  # 5æŠ˜äº¤å‰éªŒè¯ç”ŸæˆåŸºæ¨¡å‹çš„é¢„æµ‹\n",
    "    stack_method='predict_proba'  # ç°åœ¨æ‰€æœ‰åŸºæ¨¡å‹éƒ½æ”¯æŒpredict_proba\n",
    ")\n",
    "\n",
    "# å°è£…é¢„å¤„ç†+å †å æ¨¡å‹çš„ç®¡é“\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', stacking_clf)\n",
    "])\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ==============================================\n",
    "# 6. æ¨¡å‹è¯„ä¼°ï¼ˆå‡†ç¡®ç‡å¤§å¹…æå‡ï¼‰\n",
    "# ==============================================\n",
    "# éªŒè¯é›†é¢„æµ‹\n",
    "y_pred = model_pipeline.predict(X_val)\n",
    "y_pred_proba = model_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# è¾“å‡ºè¯„ä¼°æŒ‡æ ‡\n",
    "print(\"\\nğŸ¯ ä¼˜åŒ–åæ¨¡å‹æ€§èƒ½è¯„ä¼°\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"éªŒè¯é›†å‡†ç¡®ç‡: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(f\"éªŒè¯é›†AUC: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "print(\"\\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_val, y_pred, target_names=['æ­»äº¡', 'ç”Ÿå­˜']))\n",
    "\n",
    "# æ··æ·†çŸ©é˜µ+ROCæ›²çº¿å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['æ­»äº¡', 'ç”Ÿå­˜'], yticklabels=['æ­»äº¡', 'ç”Ÿå­˜'], ax=axes[0])\n",
    "axes[0].set_title('æ··æ·†çŸ©é˜µ', fontsize=12)\n",
    "axes[0].set_ylabel('çœŸå®æ ‡ç­¾')\n",
    "axes[0].set_xlabel('é¢„æµ‹æ ‡ç­¾')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "axes[1].set_xlabel('å‡æ­£ç‡')\n",
    "axes[1].set_ylabel('çœŸæ­£ç‡')\n",
    "axes[1].set_title('ROCæ›²çº¿')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==============================================\n",
    "# 7. ä¿å­˜æ¨¡å‹+é¢„æµ‹æµ‹è¯•é›†\n",
    "# ==============================================\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "model_save_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\titanic_stacking_model.pkl'\n",
    "joblib.dump(model_pipeline, model_save_path)\n",
    "print(f\"\\nâœ… æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{model_save_path}\")\n",
    "\n",
    "# æµ‹è¯•é›†é¢„æµ‹\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "y_test_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ç”Ÿæˆé¢„æµ‹ç»“æœ\n",
    "result = pd.DataFrame({\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': y_test_pred.astype(int),\n",
    "    'Survived_Probability': y_test_proba\n",
    "})\n",
    "result_save_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\optimized_predict_result.csv'\n",
    "result.to_csv(result_save_path, index=False)\n",
    "print(f\"âœ… ä¼˜åŒ–åé¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ï¼š{result_save_path}\")\n",
    "print(\"\\nğŸ“Œ æµ‹è¯•é›†å‰5æ¡é¢„æµ‹ç»“æœï¼š\")\n",
    "print(result.head())"
   ],
   "id": "bc219494f65837c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3f5a0e1cd72b861",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
