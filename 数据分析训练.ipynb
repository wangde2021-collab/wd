{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print('hello world')",
   "id": "89d2a32571133baa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = input()\n",
    "if a=='1':\n",
    "    print('1')\n",
    "else:\n",
    "    print('0')"
   ],
   "id": "62cc8bbb28f11452",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "PCA-ä¸»æˆåˆ†åˆ†æï¼šé€šè¿‡æ­£äº¤å˜æ¢å°†ä¸€ç»„å¯èƒ½å­˜åœ¨çº¿æ€§ç›¸å…³çš„æ•°æ®è½¬æ¢ä¸ºä¸€ç»„çº¿æ€§ä¸ç›¸å…³çš„ç‰¹å¾ï¼Œè½¬æ¢åçš„è¿™ç»„å˜é‡å«ä¸»æˆåˆ†ï¼Œæœ€é‡è¦çš„é™ç»´æ–¹æ³•ä¹‹ä¸€",
   "id": "2f1dcf397c60aaab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_iris\n",
    "x,y = load_iris(return_X_y=True)\n",
    "#print(y)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " # åˆå§‹åŒ–æ•°æ®æ ‡å‡†åŒ–å¤„ç†å™¨\n",
    "ss = StandardScaler()\n",
    "#æ ‡å‡†åŒ–æ•°æ®ç‰¹å¾\n",
    "X = ss.fit_transform(x)\n",
    "from   sklearn.decomposition import PCA\n",
    "# åˆå§‹åŒ–ä¸»æˆåˆ†åˆ†æå™¨ï¼Œè®¾å®šç»´åº¦ä¸º2\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "from matplotlib import pyplot as plt\n",
    "color = ['red', 'blue','green']\n",
    "markers = ['o','^','s']\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "for i in range(len(X)):\n",
    "    plt.scatter(X[i][0],X[i][1],color=color[y[i]],marker=markers[y[i]])\n",
    "plt.show()"
   ],
   "id": "1320549530f3f71d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ecb32046f312bfe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X,y = load_iris(return_X_y=True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "from sklearn.manifold import Isomap\n",
    "isomap=Isomap(n_neighbors=2)\n",
    "X=isomap.fit_transform(X)\n",
    "from matplotlib import pyplot as plt\n",
    "color = ['red', 'blue','green']\n",
    "markers = ['o','^','s']\n",
    "plt.figure(dpi=300)\n",
    "for i in range(len(X)):\n",
    "    plt.scatter(X[i,0],X[i,1],color=color[y[i]],marker=markers[y[i]])\n",
    "plt.show()\n"
   ],
   "id": "5b9dea5b480fd570",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train_data =   pd.read_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\test.csv')"
   ],
   "id": "80954493a3fb7528",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data.info()",
   "id": "a30f566bd9636403",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_data.info()",
   "id": "262f91728a1f3cf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def data_preprocess(df):\n",
    "    df = df.drop(columns=['Cabin','Ticket','Name'],axis=1)\n",
    "    df = df.fillna({'Age':df['Age'].median(),'Fare':df['Fare'].mean(),'Embarked':df['Embarked'].value_counts().idxmax()})\n",
    "    return df\n",
    "train_data = data_preprocess(train_data)\n",
    "test_data = data_preprocess(test_data)"
   ],
   "id": "7db5e1190b77cf6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = train_data.drop(columns=['Survived','PassengerId' ],axis=1)\n",
    "y_train = train_data['Survived']\n",
    "X_test = test_data.drop(columns=['PassengerId' ],axis=1)\n",
    "num_X_train = X_train[['Age','Fare','SibSp','Parch']].values\n",
    "num_X_test = test_data[['Age','Fare','SibSp','Parch']].values"
   ],
   "id": "3bb260d70f061eb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "cate_X_train = ohe.fit_transform(X_train[['Pclass','Sex','Embarked']]).todense()\n",
    "cate_X_test = ohe.transform(X_test[['Pclass','Sex','Embarked']]).todense()"
   ],
   "id": "70606c66bf7ed4bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'n_estimators':[10,20,30,40,50,60,70,80,90,100],'criterion':['gini','entropy']}\n",
    "rfc = RandomForestClassifier()\n",
    "clf = GridSearchCV(estimator=rfc,param_grid=parameters,scoring='accuracy',n_jobs=4)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ],
   "id": "c5f4def5ec6cc66f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\test.csv')\n",
    "\n",
    "def data_preprocess(df):\n",
    "    df = df.drop(columns=['Cabin','Ticket','Name'],axis=1)\n",
    "    df = df.fillna({'Age':df['Age'].median(),\n",
    "                    'Fare':df['Fare'].mean(),\n",
    "                    'Embarked':df['Embarked'].value_counts().idxmax()})\n",
    "    return df\n",
    "\n",
    "train_data = data_preprocess(train_data)\n",
    "test_data = data_preprocess(test_data)\n",
    "\n",
    "X_train = train_data.drop(columns=['Survived','PassengerId' ],axis=1)\n",
    "y_train = train_data['Survived']\n",
    "X_test = test_data.drop(columns=['PassengerId' ],axis=1)\n",
    "\n",
    "num_X_train = X_train[['Age','Fare','SibSp','Parch']].values\n",
    "num_X_test = test_data[['Age','Fare','SibSp','Parch']].values\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "cate_X_train = ohe.fit_transform(X_train[['Pclass','Sex','Embarked']]).todense()\n",
    "cate_X_test = ohe.transform(X_test[['Pclass','Sex','Embarked']]).todense()\n",
    "\n",
    "import numpy as np\n",
    "X_train_final = np.hstack([num_X_train, cate_X_train])\n",
    "X_test_final = np.hstack([num_X_test, cate_X_test])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators':[10,20,30,40,50,60,70,80,90,100],\n",
    "    'criterion':['gini','entropy']\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "clf = GridSearchCV(estimator=rfc, param_grid=parameters,\n",
    "                   scoring='accuracy', n_jobs=4)\n",
    "\n",
    "clf.fit(X_train_final, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n"
   ],
   "id": "721375870be664e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\test.csv')\n",
    "\n",
    "def data_preprocess(df):\n",
    "    df = df.drop(columns=['Cabin','Ticket','Name'],axis=1)\n",
    "    df = df.fillna({'Age':df['Age'].median(),\n",
    "                    'Fare':df['Fare'].mean(),\n",
    "                    'Embarked':df['Embarked'].value_counts().idxmax()})\n",
    "    return df\n",
    "\n",
    "train_data = data_preprocess(train_data)\n",
    "test_data = data_preprocess(test_data)\n",
    "\n",
    "X_train = train_data.drop(columns=['Survived','PassengerId' ],axis=1)\n",
    "y_train = train_data['Survived']\n",
    "X_test = test_data.drop(columns=['PassengerId' ],axis=1)\n",
    "\n",
    "num_X_train = X_train[['Age','Fare','SibSp','Parch']].values\n",
    "num_X_test = test_data[['Age','Fare','SibSp','Parch']].values\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "cate_X_train = ohe.fit_transform(X_train[['Pclass','Sex','Embarked']]).todense()\n",
    "cate_X_test = ohe.transform(X_test[['Pclass','Sex','Embarked']]).todense()\n",
    "\n",
    "import numpy as np\n",
    "X_train_final = np.hstack([num_X_train, cate_X_train])\n",
    "X_test_final = np.hstack([num_X_test, cate_X_test])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators':[10,20,30,40,50,60,70,80,90,100],\n",
    "    'criterion':['gini','entropy']\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "clf = GridSearchCV(estimator=rfc, param_grid=parameters,\n",
    "                   scoring='accuracy', n_jobs=4)\n",
    "\n",
    "clf.fit(X_train_final, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n"
   ],
   "id": "7b09b7861563c7ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\test.csv')\n",
    "\n",
    "def data_preprocess(df):\n",
    "    df = df.drop(columns=['Cabin','Ticket','Name'],axis=1)\n",
    "    df = df.fillna({\n",
    "        'Age':df['Age'].median(),\n",
    "        'Fare':df['Fare'].mean(),\n",
    "        'Embarked':df['Embarked'].value_counts().idxmax()\n",
    "    })\n",
    "    return df\n",
    "\n",
    "train_data = data_preprocess(train_data)\n",
    "test_data = data_preprocess(test_data)\n",
    "\n",
    "X_train = train_data.drop(columns=['Survived','PassengerId'],axis=1)\n",
    "y_train = train_data['Survived']\n",
    "X_test = test_data.drop(columns=['PassengerId'],axis=1)\n",
    "\n",
    "num_X_train = X_train[['Age','Fare','SibSp','Parch']].values\n",
    "num_X_test = test_data[['Age','Fare','SibSp','Parch']].values\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "cate_X_train = ohe.fit_transform(X_train[['Pclass','Sex','Embarked']]).toarray()\n",
    "cate_X_test = ohe.transform(X_test[['Pclass','Sex','Embarked']]).toarray()\n",
    "\n",
    "import numpy as np\n",
    "X_train_final = np.hstack([num_X_train, cate_X_train])\n",
    "X_test_final = np.hstack([num_X_test, cate_X_test])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators':[10,20,30,40,50,60,70,80,90,100],\n",
    "              'criterion':['gini','entropy']}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "clf = GridSearchCV(estimator=rfc, param_grid=parameters, scoring='accuracy', n_jobs=4)\n",
    "\n",
    "clf.fit(X_train_final, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n"
   ],
   "id": "88bbc20a96d9677b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_predict = clf.predict(X_test_final)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],  # æ³¨æ„å¤§å°å†™æ˜¯ PassengerId\n",
    "    'Survived': y_predict\n",
    "})\n",
    "\n",
    "submission.to_csv(r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\new_submission.csv', index=False)\n"
   ],
   "id": "e32ba268daa9ea98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ==============================================\n",
    "# 1. å¯¼å…¥æ‰©å±•åº“ï¼ˆæ–°å¢LightGBMã€ç½‘æ ¼æœç´¢ã€æ­£åˆ™åŒ–ç­‰ï¼‰\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import re  # ç”¨äºæå–å§“åä¸­çš„å¤´è¡”\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ==============================================\n",
    "# 2. å¢å¼ºç‰ˆç‰¹å¾å·¥ç¨‹ï¼ˆæ ¸å¿ƒä¼˜åŒ–ç‚¹ï¼‰\n",
    "# ==============================================\n",
    "def load_and_engineer_data(train_path, test_path=None):\n",
    "    \"\"\"åŠ è½½æ•°æ®å¹¶æ‰§è¡Œç‰¹å¾å·¥ç¨‹ï¼Œè¿”å›å¤„ç†åçš„è®­ç»ƒ/æµ‹è¯•æ•°æ®\"\"\"\n",
    "    # åŠ è½½è®­ç»ƒé›†\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df = df_train.copy()\n",
    "    test_flag = False\n",
    "    if test_path:\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        df_test['Survived'] = -1  # æ ‡è®°æµ‹è¯•é›†æ ‡ç­¾\n",
    "        df = pd.concat([df, df_test], ignore_index=True)\n",
    "        test_flag = True\n",
    "\n",
    "    # -------- ç¼ºå¤±å€¼å¡«å……ï¼ˆç²¾ç»†åŒ–ï¼‰ --------\n",
    "    # å¹´é¾„ï¼šæŒ‰å¤´è¡”+èˆ±ä½åˆ†ç»„å¡«å……ï¼ˆæ¯”ä»…Pclass+Sexæ›´ç²¾å‡†ï¼‰\n",
    "    df['Title'] = df['Name'].apply(lambda x: re.findall(r'([A-Za-z]+)\\.', x)[0])  # æå–å¤´è¡”\n",
    "    df['Age'] = df.groupby(['Pclass', 'Title'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    # ç™»èˆ¹æ¸¯å£ï¼šä¼—æ•°å¡«å……\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    # ç¥¨ä»·ï¼šæŒ‰èˆ±ä½åˆ†ç»„å¡«å……\n",
    "    df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    # èˆ±ä½ï¼šå¡«å……Uå¹¶æå–é¦–å­—æ¯ï¼Œåˆå¹¶ç¨€æœ‰èˆ±ä½\n",
    "    df['Cabin'] = df['Cabin'].fillna('U').apply(lambda x: x[0] if pd.notna(x) else 'U')\n",
    "    rare_cabins = df['Cabin'].value_counts()[df['Cabin'].value_counts() < 10].index\n",
    "    df['Cabin'] = df['Cabin'].replace(rare_cabins, 'R')  # ç¨€æœ‰èˆ±ä½åˆå¹¶ä¸ºR\n",
    "\n",
    "    # -------- è¡ç”Ÿç‰¹å¾ï¼ˆæ ¸å¿ƒï¼ï¼‰ --------\n",
    "    # 1. å®¶åº­è§„æ¨¡ï¼šå…„å¼Ÿå§å¦¹+çˆ¶æ¯å­å¥³+è‡ªå·±\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    # 2. æ˜¯å¦å•èº«\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    # 3. å¤´è¡”åˆå¹¶ï¼ˆå‡å°‘ç±»åˆ«æ•°ï¼‰\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Don': 'Noble', 'Sir': 'Noble', 'Lady': 'Noble', 'Countess': 'Noble', 'Dona': 'Noble',\n",
    "        'Dr': 'Professional', 'Rev': 'Professional', 'Col': 'Military', 'Major': 'Military', 'Capt': 'Military',\n",
    "        'Ms': 'Miss', 'Mlle': 'Miss', 'Mme': 'Mrs'\n",
    "    }\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "    # 4. ç¥¨ä»·åˆ†ç®±ï¼ˆæ•æ‰éçº¿æ€§å…³ç³»ï¼‰\n",
    "    df['FareBin'] = pd.cut(df['Fare'], bins=[0, 10, 30, 100, 600], labels=['Low', 'Mid', 'High', 'Luxury'])\n",
    "    # 5. å¹´é¾„åˆ†ç®±\n",
    "    df['AgeBin'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], labels=['Child', 'Teen', 'Adult', 'Middle', 'Elder'])\n",
    "\n",
    "    # -------- ç­›é€‰ç‰¹å¾ --------\n",
    "    # æœ€ç»ˆç‰¹å¾åˆ—è¡¨ï¼ˆå«è¡ç”Ÿç‰¹å¾ï¼‰\n",
    "    core_features = [\n",
    "        'Pclass', 'Sex', 'Embarked', 'Cabin', 'Title',\n",
    "        'FamilySize', 'IsAlone', 'FareBin', 'AgeBin'\n",
    "    ]\n",
    "    target = 'Survived'\n",
    "\n",
    "    # æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›†\n",
    "    if test_flag:\n",
    "        df_train_processed = df[df[target] != -1].copy()\n",
    "        df_test_processed = df[df[target] == -1].copy()\n",
    "        X_train = df_train_processed[core_features]\n",
    "        y_train = df_train_processed[target]\n",
    "        X_test = df_test_processed[core_features]\n",
    "        passenger_id = df_test_processed['PassengerId']\n",
    "        return X_train, y_train, X_test, passenger_id\n",
    "    else:\n",
    "        X = df[core_features]\n",
    "        y = df[target]\n",
    "        return X, y\n",
    "\n",
    "# åŠ è½½æ•°æ®å¹¶æ‰§è¡Œç‰¹å¾å·¥ç¨‹ï¼ˆä¿®æ”¹ä¸ºä½ çš„è·¯å¾„ï¼‰\n",
    "train_path = r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\train.csv'\n",
    "test_path = r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\test.csv'\n",
    "X, y, X_test, passenger_id = load_and_engineer_data(train_path, test_path)\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆæ¯”åŸä»£ç çš„train_test_splitæ›´åˆç†ï¼‰\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ==============================================\n",
    "# 3. é¢„å¤„ç†ç®¡é“ï¼ˆå…¨å±€ç»Ÿä¸€ï¼‰\n",
    "# ==============================================\n",
    "# å®šä¹‰ç±»åˆ«ç‰¹å¾ï¼ˆæ‰€æœ‰éæ•°å€¼ç‰¹å¾ï¼‰\n",
    "categorical_features = X_train.columns.tolist()  # ç»ç‰¹å¾å·¥ç¨‹åå‡ä¸ºç±»åˆ«ç‰¹å¾\n",
    "# é¢„å¤„ç†ï¼šç‹¬çƒ­ç¼–ç ï¼ˆå¿½ç•¥æœªçŸ¥ç±»åˆ«ï¼‰\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ==============================================\n",
    "# 4. é‡æ„è°ƒå‚å‡½æ•°ï¼ˆæ ¸å¿ƒï¼šç”¨Pipelineå°è£…é¢„å¤„ç†+æ¨¡å‹ï¼Œæ¶ˆé™¤ç‰¹å¾åè­¦å‘Šï¼‰\n",
    "# ==============================================\n",
    "def tune_model(preprocessor, model, param_grid, X, y):\n",
    "    \"\"\"\n",
    "    ç½‘æ ¼æœç´¢è°ƒå‚ï¼Œå°è£…é¢„å¤„ç†+æ¨¡å‹çš„Pipeline\n",
    "    :param preprocessor: å…¨å±€é¢„å¤„ç†ç®¡é“\n",
    "    :param model: å¾…è°ƒå‚çš„åŸºæ¨¡å‹\n",
    "    :param param_grid: è°ƒå‚ç½‘æ ¼ï¼ˆæ³¨æ„å‚æ•°åè¦åŠ æ¨¡å‹åˆ«å__ï¼‰\n",
    "    :param X: åŸå§‹ç‰¹å¾ï¼ˆDataFrameï¼Œå¸¦ç‰¹å¾åï¼‰\n",
    "    :param y: æ ‡ç­¾\n",
    "    :return: æœ€ä¼˜Pipelineæ¨¡å‹\n",
    "    \"\"\"\n",
    "    # å°è£…é¢„å¤„ç†+æ¨¡å‹çš„Pipeline\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # ç½‘æ ¼æœç´¢\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,  # 5æŠ˜äº¤å‰éªŒè¯\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # å¹¶è¡Œè®¡ç®—\n",
    "        verbose=0\n",
    "    )\n",
    "    grid_search.fit(X, y)  # è¾“å…¥æ˜¯å¸¦ç‰¹å¾åçš„DataFrameï¼Œç”±Pipelineå†…éƒ¨å¤„ç†\n",
    "    print(f\"âœ… {model.__class__.__name__} æœ€ä¼˜å‚æ•°ï¼š{grid_search.best_params_}\")\n",
    "    print(f\"âœ… äº¤å‰éªŒè¯æœ€ä¼˜å‡†ç¡®ç‡ï¼š{grid_search.best_score_:.4f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# -------- å®šä¹‰åŸºæ¨¡å‹åŠè°ƒå‚ç½‘æ ¼ï¼ˆå‚æ•°åè¦åŠ model__å‰ç¼€ï¼ï¼‰ --------\n",
    "# XGBoostè°ƒå‚\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_param = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [3, 5],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__subsample': [0.8, 1.0]\n",
    "}\n",
    "best_xgb_pipeline = tune_model(preprocessor, xgb, xgb_param, X_train, y_train)\n",
    "# æå–è°ƒä¼˜åçš„XGBæ¨¡å‹ï¼ˆç”¨äºå †å ï¼‰\n",
    "best_xgb = best_xgb_pipeline.named_steps['model']\n",
    "\n",
    "# LightGBMè°ƒå‚ï¼ˆæ–°å¢é«˜æ•ˆæ¨¡å‹ï¼‰\n",
    "lgb = LGBMClassifier(random_state=42, verbose=-1)\n",
    "lgb_param = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [3, 5],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__num_leaves': [31, 63]\n",
    "}\n",
    "best_lgb_pipeline = tune_model(preprocessor, lgb, lgb_param, X_train, y_train)\n",
    "# æå–è°ƒä¼˜åçš„LGBæ¨¡å‹ï¼ˆç”¨äºå †å ï¼‰\n",
    "best_lgb = best_lgb_pipeline.named_steps['model']\n",
    "\n",
    "# éšæœºæ£®æ—è°ƒå‚\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [5, 8],\n",
    "    'model__min_samples_split': [2, 5]\n",
    "}\n",
    "best_rf_pipeline = tune_model(preprocessor, rf, rf_param, X_train, y_train)\n",
    "# æå–è°ƒä¼˜åçš„RFæ¨¡å‹ï¼ˆç”¨äºå †å ï¼‰\n",
    "best_rf = best_rf_pipeline.named_steps['model']\n",
    "\n",
    "# ==============================================\n",
    "# 5. å †å é›†æˆæ¨¡å‹ï¼ˆStackingï¼‰- æ— è­¦å‘Šç‰ˆæœ¬\n",
    "# ==============================================\n",
    "# å®šä¹‰åŸºæ¨¡å‹åˆ—è¡¨ï¼ˆæ‰€æœ‰æ¨¡å‹å‡ä¸ºè°ƒä¼˜åçš„å®ä¾‹ï¼‰\n",
    "base_models = [\n",
    "    ('xgb', best_xgb),\n",
    "    ('lgb', best_lgb),\n",
    "    ('rf', best_rf),\n",
    "    ('svc', SVC(probability=True, random_state=42)),  # SVMï¼ˆå¸¦æ¦‚ç‡ï¼‰\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=500))  # é€»è¾‘å›å½’\n",
    "]\n",
    "\n",
    "# å †å é›†æˆï¼šäºŒçº§æ¨¡å‹ç”¨é€»è¾‘å›å½’ï¼Œå°è£…å…¨å±€é¢„å¤„ç†ç®¡é“\n",
    "stacking_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=LogisticRegression(random_state=42, max_iter=500),\n",
    "        cv=5,\n",
    "        stack_method='predict_proba'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# è®­ç»ƒå †å æ¨¡å‹\n",
    "stacking_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ==============================================\n",
    "# 6. æ¨¡å‹è¯„ä¼°ï¼ˆå‡†ç¡®ç‡å¤§å¹…æå‡ï¼Œæ— è­¦å‘Šï¼‰\n",
    "# ==============================================\n",
    "# éªŒè¯é›†é¢„æµ‹\n",
    "y_pred = stacking_pipeline.predict(X_val)\n",
    "y_pred_proba = stacking_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# è¾“å‡ºè¯„ä¼°æŒ‡æ ‡\n",
    "print(\"\\nğŸ¯ ä¼˜åŒ–åæ¨¡å‹æ€§èƒ½è¯„ä¼°\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"éªŒè¯é›†å‡†ç¡®ç‡: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(f\"éªŒè¯é›†AUC: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "print(\"\\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_val, y_pred, target_names=['æ­»äº¡', 'ç”Ÿå­˜']))\n",
    "\n",
    "# æ··æ·†çŸ©é˜µ+ROCæ›²çº¿å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['æ­»äº¡', 'ç”Ÿå­˜'], yticklabels=['æ­»äº¡', 'ç”Ÿå­˜'], ax=axes[0])\n",
    "axes[0].set_title('æ··æ·†çŸ©é˜µ', fontsize=12)\n",
    "axes[0].set_ylabel('çœŸå®æ ‡ç­¾')\n",
    "axes[0].set_xlabel('é¢„æµ‹æ ‡ç­¾')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "axes[1].set_xlabel('å‡æ­£ç‡')\n",
    "axes[1].set_ylabel('çœŸæ­£ç‡')\n",
    "axes[1].set_title('ROCæ›²çº¿')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==============================================\n",
    "# 7. ä¿å­˜æ¨¡å‹+é¢„æµ‹æµ‹è¯•é›†\n",
    "# ==============================================\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "model_save_path = r'C:\\Users\\wangd\\Desktop\\æ³°å¦å°¼å…‹å·\\titanic_stacking_model.pkl'\n",
    "joblib.dump(stacking_pipeline, model_save_path)\n",
    "print(f\"\\nâœ… æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{model_save_path}\")\n",
    "\n",
    "# æµ‹è¯•é›†é¢„æµ‹\n",
    "y_test_pred = stacking_pipeline.predict(X_test)\n",
    "y_test_proba = stacking_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ç”Ÿæˆé¢„æµ‹ç»“æœ\n",
    "result = pd.DataFrame({\n",
    "    'PassengerId': passenger_id,\n",
    "    'Survived': y_test_pred.astype(int),\n",
    "    'Survived_Probability': y_test_proba\n",
    "})\n",
    "result_save_path = r'C:\\Users\\wangd\\Desktop\\kaggle\\1_æ³°å¦å°¼å…‹å·\\optimized_predict_result.csv'\n",
    "result.to_csv(result_save_path, index=False)\n",
    "print(f\"âœ… ä¼˜åŒ–åé¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ï¼š{result_save_path}\")\n",
    "print(\"\\nğŸ“Œ æµ‹è¯•é›†å‰5æ¡é¢„æµ‹ç»“æœï¼š\")\n",
    "print(result.head())"
   ],
   "id": "276bbe45ba0d7849",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install numpy pandas tushare akshare jupyter mplfinance plotly",
   "id": "251ee8435936f962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6900c6b54aaa417b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "data = np.random.randint(50, 150, size=100)\n",
    "ts = pd.Series(data, index=dates)\n",
    "\n",
    "# # ä¸åŒé‡é‡‡æ ·æ–¹æ³•\n",
    "# weekly_mean = ts.resample('W').mean()   # å‘¨å¹³å‡\n",
    "# weekly_sum = ts.resample('W').sum()     # å‘¨æ€»å’Œ\n",
    "# weekly_max = ts.resample('W').max()     # å‘¨æœ€å¤§å€¼\n",
    "# weekly_min = ts.resample('W').min()     # å‘¨æœ€å°å€¼\n",
    "# weekly_ohlc = ts.resample('W').ohlc()   # OHLC (å¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜)\n",
    "#\n",
    "# print(\"å‘¨å¹³å‡(å‰5å‘¨):\")\n",
    "# print(weekly_mean.head())\n",
    "#\n",
    "# print(\"\\nOHLCæ•°æ®(å‰5å‘¨):\")\n",
    "# print(weekly_ohlc.head())"
   ],
   "id": "f33e02ce82db0e28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a= ts.resample('Q')\n",
    "print(a)"
   ],
   "id": "9102dde693bd41f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pip install glassnode",
   "id": "639b1d7991f7826d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pip install akshare",
   "id": "bb768dafb87a69ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "proxy = {'http': 'http://127.0.0.1:7890', 'https': 'http://127.0.0.1:7890'}\n",
    "try:\n",
    "    resp = requests.get('https://api.binance.com/api/v3/exchangeInfo', proxies=proxy, timeout=10)\n",
    "    print(\"ä»£ç†å¯ç”¨ï¼Œå“åº”çŠ¶æ€ç ï¼š\", resp.status_code)\n",
    "except Exception as e:\n",
    "    print(\"ä»£ç†ä¸å¯ç”¨ï¼š\", e)"
   ],
   "id": "bd2662f2733398c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "# æ›¿æ¢æˆä½ çš„ä»£ç†ï¼ˆæ¯”å¦‚Clashçš„HTTPä»£ç†ï¼‰\n",
    "proxy = {\n",
    "    'http': 'http://127.0.0.1:7890',\n",
    "    'https': 'http://127.0.0.1:7890'\n",
    "}\n",
    "\n",
    "try:\n",
    "    resp = requests.get('https://api.binance.com/api/v3/exchangeInfo', proxies=proxy, timeout=10)\n",
    "    print(\"ä»£ç†å¯ç”¨ï¼å“åº”å†…å®¹ï¼š\", resp.text[:200])  # æ‰“å°å‰200å­—ç¬¦\n",
    "except Exception as e:\n",
    "    print(\"ä»£ç†è¿˜æ˜¯ä¸è¡Œï¼š\", e)"
   ],
   "id": "c2943cba8cf7455f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "proxy = {\n",
    "    \"http\": \"http://127.0.0.1:7890\",\n",
    "    \"https\": \"http://127.0.0.1:7890\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    r = requests.get(\"https://www.google.com\", proxies=proxy, timeout=5)\n",
    "    print(\"ä»£ç†å¯ç”¨:\", r.status_code)\n",
    "except Exception as e:\n",
    "    print(\"ä»£ç†ä¸å¯ç”¨:\", e)\n"
   ],
   "id": "8eadf30318362e60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ccxt\n",
    "import os\n",
    "from dotenv import load_dotenv  # ç”¨äºåŠ è½½ç¯å¢ƒå˜é‡ï¼ˆé¿å…ç¡¬ç¼–ç å¯†é’¥ï¼‰\n",
    "\n",
    "# åŠ è½½.envæ–‡ä»¶ï¼ˆéœ€åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.envï¼Œå†™å…¥ï¼šBINANCE_API_KEY=xxx; BINANCE_SECRET=xxxï¼‰\n",
    "load_dotenv()\n",
    "\n",
    "# æ–¹å¼1ï¼šä»…è·å–è¡Œæƒ…ï¼ˆæ— éœ€å¯†é’¥ï¼Œæœ€å¸¸ç”¨ï¼‰\n",
    "exchange = ccxt.binance({\n",
    "    'enableRateLimit': True,  # å¿…å¼€ï¼è‡ªåŠ¨é™é€Ÿï¼Œé˜²æ­¢è¢«äº¤æ˜“æ‰€å°ç¦\n",
    "    'timeout': 30000,         # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆ30ç§’ï¼‰\n",
    "    'verbose': False          # å…³é—­è°ƒè¯•æ—¥å¿—ï¼ˆTrueå¯æŸ¥è¯·æ±‚è¯¦æƒ…ï¼‰\n",
    "})\n",
    "\n",
    "# æ–¹å¼2ï¼šéœ€è´¦æˆ·/ä¸‹å•æ“ä½œï¼ˆé…ç½®APIå¯†é’¥ï¼‰\n",
    "exchange = ccxt.binance({\n",
    "    'apiKey': os.getenv('BINANCE_API_KEY'),\n",
    "    'secret': os.getenv('BINANCE_SECRET'),\n",
    "    'enableRateLimit': True,\n",
    "    'testnet': True  # æµ‹è¯•ç½‘ï¼ˆæ— çœŸå®èµ„é‡‘ï¼Œä¼˜å…ˆç”¨æµ‹è¯•ç½‘ç»ƒæ‰‹ï¼‰\n",
    "})\n",
    "\n",
    "# éªŒè¯åˆå§‹åŒ–æˆåŠŸ\n",
    "print(f\"äº¤æ˜“æ‰€åç§°ï¼š{exchange.name}\")\n",
    "print(f\"æ”¯æŒçš„æ—¶é—´ç²’åº¦ï¼š{exchange.timeframes}\")  # å¦‚1mã€1hã€1d\n",
    "print(f\"æ”¯æŒçš„äº¤æ˜“å¯¹ç¤ºä¾‹ï¼š{exchange.symbols[:3]}\")  # æ‰“å°å‰3ä¸ªäº¤æ˜“å¯¹"
   ],
   "id": "1a6dc9ba3629906e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ccxt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "exchange = ccxt.binance({\n",
    "    'enableRateLimit': True,\n",
    "    'timeout': 30000,\n",
    "    'testnet': True,\n",
    "    'apiKey': os.getenv(\"BINANCE_API_KEY\"),\n",
    "    'secret': os.getenv(\"BINANCE_SECRET\"),\n",
    "})\n",
    "\n",
    "# å¿…é¡»å…ˆåŠ è½½å¸‚åœº\n",
    "try:\n",
    "    markets = exchange.load_markets()\n",
    "    print(\"äº¤æ˜“æ‰€è¿æ¥æˆåŠŸï¼\")\n",
    "except Exception as e:\n",
    "    print(\"äº¤æ˜“æ‰€è¿æ¥å¤±è´¥ï¼š\", e)\n",
    "    exit()\n",
    "\n",
    "print(f\"äº¤æ˜“æ‰€åç§°ï¼š{exchange.name}\")\n",
    "print(f\"æ”¯æŒçš„æ—¶é—´ç²’åº¦ï¼š{exchange.timeframes}\")\n",
    "\n",
    "# ç¡®ä¿symbolsåŠ è½½æˆåŠŸ\n",
    "if exchange.symbols:\n",
    "    print(f\"æ”¯æŒçš„äº¤æ˜“å¯¹ç¤ºä¾‹ï¼š{exchange.symbols[:3]}\")\n",
    "else:\n",
    "    print(\"æœªèƒ½åŠ è½½äº¤æ˜“å¯¹åˆ—è¡¨\")\n"
   ],
   "id": "dfcbd816e433c195",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# åŸºç¡€å‚æ•°\n",
    "symbol = 'BTC/USDT'  # äº¤æ˜“å¯¹ï¼ˆæ‰€æœ‰äº¤æ˜“æ‰€ç»Ÿä¸€æ ¼å¼ï¼šBASE/QUOTEï¼‰\n",
    "timeframe = '1h'     # æ—¶é—´ç²’åº¦ï¼š1m(1åˆ†é’Ÿ)ã€1h(1å°æ—¶)ã€1d(æ—¥çº¿)\n",
    "limit = 1000         # å•æ¬¡æœ€å¤§è¯·æ±‚é‡ï¼ˆBinance 1m Kçº¿ä¸Šé™1500ï¼‰\n",
    "\n",
    "# ç¤ºä¾‹1ï¼šè·å–æœ€æ–°100æ ¹1å°æ—¶Kçº¿\n",
    "ohlcv_latest = exchange.fetch_ohlcv(symbol, timeframe, limit=100)\n",
    "# è½¬æ¢ä¸ºDataFrameï¼ˆæ–¹ä¾¿åˆ†æï¼‰\n",
    "df = pd.DataFrame(\n",
    "    ohlcv_latest,\n",
    "    columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    ")\n",
    "# æ—¶é—´æˆ³è½¬å¯è¯»æ ¼å¼ï¼ˆæ¯«ç§’â†’datetimeï¼‰\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "print(\"æœ€æ–°100æ ¹1å°æ—¶Kçº¿ï¼š\")\n",
    "print(df[['datetime', 'open', 'close', 'volume']].head())\n",
    "\n",
    "# ç¤ºä¾‹2ï¼šè·å–æŒ‡å®šæ—¶é—´æ®µKçº¿ï¼ˆå¦‚2024å¹´1æœˆ1æ—¥è‡³ä»Šï¼‰\n",
    "since = exchange.parse8601('2024-01-01T00:00:00Z')  # è½¬æ¢ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³\n",
    "ohlcv_range = exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=limit)\n",
    "df_range = pd.DataFrame(ohlcv_range, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df_range['datetime'] = pd.to_datetime(df_range['timestamp'], unit='ms')\n",
    "print(f\"\\n2024å¹´è‡³ä»Š1å°æ—¶Kçº¿æ•°é‡ï¼š{len(df_range)}\")\n",
    "\n",
    "# ä¿å­˜Kçº¿åˆ°CSVï¼ˆæ–¹ä¾¿åç»­åˆ†æï¼‰\n",
    "df_range.to_csv('btc_usdt_1h_2024.csv', index=False)"
   ],
   "id": "e28a5013a14e7cae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. å®æ—¶Tickerï¼ˆæœ€æ–°ä»·ã€æ¶¨è·Œå¹…ã€æˆäº¤é‡ç­‰ï¼‰\n",
    "ticker = exchange.fetch_ticker(symbol)\n",
    "print(\"\\nBTC/USDTå®æ—¶è¡Œæƒ…ï¼š\")\n",
    "print(f\"æœ€æ–°ä»·ï¼š{ticker['last']} USDT\")\n",
    "print(f\"24hæ¶¨è·Œå¹…ï¼š{ticker['percentage']}%\")\n",
    "print(f\"24hæˆäº¤é‡ï¼š{ticker['baseVolume']} BTC\")\n",
    "print(f\"24hé«˜ä½ä»·ï¼š{ticker['high']} / {ticker['low']}\")\n",
    "\n",
    "# 2. ç›˜å£æ·±åº¦ï¼ˆOrder Bookï¼‰\n",
    "depth = exchange.fetch_order_book(symbol, limit=10)  # ä¹°å–ç›˜å„10æ¡£\n",
    "print(\"\\nBTC/USDTä¹°ç›˜å‰5æ¡£ï¼ˆä»·æ ¼, æ•°é‡ï¼‰ï¼š\")\n",
    "print(depth['bids'][:5])  # ä¹°å•ï¼šä»·æ ¼é™åºï¼Œä»·é«˜è€…ä¼˜å…ˆ\n",
    "print(\"\\nBTC/USDTå–ç›˜å‰5æ¡£ï¼ˆä»·æ ¼, æ•°é‡ï¼‰ï¼š\")\n",
    "print(depth['asks'][:5])  # å–å•ï¼šä»·æ ¼å‡åºï¼Œä»·ä½è€…ä¼˜å…ˆ\n",
    "\n",
    "# 3. æœ€æ–°æˆäº¤æ˜ç»†ï¼ˆTradesï¼‰\n",
    "trades = exchange.fetch_trades(symbol, limit=5)\n",
    "print(\"\\næœ€æ–°5ç¬”æˆäº¤æ˜ç»†ï¼š\")\n",
    "for trade in trades:\n",
    "    print(f\"æ—¶é—´ï¼š{pd.to_datetime(trade['timestamp'], unit='ms')} | æ–¹å‘ï¼š{trade['side']} | ä»·æ ¼ï¼š{trade['price']} | æ•°é‡ï¼š{trade['amount']}\")"
   ],
   "id": "7d3afedce53e5b18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ====================== é…ç½®é¡¹ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰======================\n",
    "SYMBOL = 'BTC/USDT'  # äº¤æ˜“å¯¹\n",
    "TIMEFRAME = '1m'  # 1åˆ†é’Ÿæ—¶é—´ç²’åº¦\n",
    "LIMIT_PER_REQUEST = 1500  # å•æ¬¡è¯·æ±‚æœ€å¤§æ¡æ•°ï¼ˆBinance 1mä¸Šé™ï¼‰\n",
    "# è·å–å…¨é‡æ•°æ®ï¼ˆä»2017å¹´BTC/USDTä¸Šçº¿è‡³ä»Šï¼‰ï¼›è‹¥åªéœ€æœ€è¿‘æ•°æ®ï¼Œæ”¹sinceä¸º'2024-01-01T00:00:00Z'\n",
    "SINCE = '2017-08-17T00:00:00Z'\n",
    "\n",
    "# ====================== æ ¸å¿ƒé€»è¾‘ï¼šè·å–æ•°æ®å¹¶ä¿å­˜CSV ======================\n",
    "# åˆå§‹åŒ–äº¤æ˜“æ‰€ï¼ˆä»…è¡Œæƒ…è·å–ï¼Œæ— éœ€APIå¯†é’¥ï¼‰\n",
    "exchange = ccxt.binance({\n",
    "    'enableRateLimit': True,  # å¼€å¯é™é€Ÿï¼Œé¿å…è¢«äº¤æ˜“æ‰€å°ç¦\n",
    "    'timeout': 30000\n",
    "})\n",
    "\n",
    "# è½¬æ¢èµ·å§‹æ—¶é—´ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³\n",
    "start_timestamp = exchange.parse8601(SINCE)\n",
    "all_ohlcv = []  # å­˜å‚¨æ‰€æœ‰Kçº¿æ•°æ®\n",
    "\n",
    "print(\"å¼€å§‹è·å–BTC/USDT 1åˆ†é’Ÿè¡Œæƒ…æ•°æ®...\")\n",
    "while start_timestamp < exchange.milliseconds():\n",
    "    try:\n",
    "        # åˆ†æ‰¹è·å–Kçº¿æ•°æ®\n",
    "        ohlcv = exchange.fetch_ohlcv(\n",
    "            symbol=SYMBOL,\n",
    "            timeframe=TIMEFRAME,\n",
    "            since=start_timestamp,\n",
    "            limit=LIMIT_PER_REQUEST\n",
    "        )\n",
    "        if not ohlcv:  # æ— æ•°æ®åˆ™åœæ­¢\n",
    "            break\n",
    "\n",
    "        all_ohlcv.extend(ohlcv)\n",
    "        # æ›´æ–°ä¸‹ä¸€æ‰¹æ•°æ®çš„èµ·å§‹æ—¶é—´ï¼ˆæœ€åä¸€æ¡æ•°æ®çš„æ—¶é—´ + 1åˆ†é’Ÿï¼‰\n",
    "        start_timestamp = ohlcv[-1][0] + 60 * 1000\n",
    "        print(f\"å·²è·å– {len(all_ohlcv)} æ¡æ•°æ®...\")\n",
    "        time.sleep(0.1)  # é™é€Ÿä¿æŠ¤\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ä¸´æ—¶æŠ¥é”™ï¼š{e}ï¼Œ5ç§’åé‡è¯•...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "# è½¬æ¢ä¸ºDataFrameå¹¶å¤„ç†æ—¶é—´\n",
    "df = pd.DataFrame(\n",
    "    all_ohlcv,\n",
    "    columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    ")\n",
    "# æ¯«ç§’çº§æ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»æ—¶é—´æ ¼å¼\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "# å»é‡ï¼ˆé˜²æ­¢é‡å¤è¯·æ±‚å¯¼è‡´çš„æ•°æ®é‡å¤ï¼‰\n",
    "df = df.drop_duplicates(subset=['timestamp']).sort_values('timestamp')\n",
    "\n",
    "# ä¿å­˜åˆ°a.csv\n",
    "df.to_csv('a.csv', index=False, encoding='utf-8')\n",
    "print(f\"\\nâœ… æ•°æ®å·²å…¨éƒ¨ä¿å­˜åˆ°a.csvï¼\")\n",
    "print(f\"ğŸ“Š æ•°æ®æ€»é‡ï¼š{len(df)} æ¡1åˆ†é’ŸKçº¿\")\n",
    "print(f\"ğŸ•’ æ—¶é—´èŒƒå›´ï¼š{df['datetime'].min()} è‡³ {df['datetime'].max()}\")"
   ],
   "id": "8e4504266bdf1063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pip install akshare",
   "id": "aa2e4464d7f55efb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# ====================== æ ¸å¿ƒé€»è¾‘ï¼šè·å–BTC/USDT 1åˆ†é’Ÿè¡Œæƒ…å¹¶ä¿å­˜CSV ======================\n",
    "# è·å–BTC/USDT 1åˆ†é’Ÿçº§è¡Œæƒ…ï¼ˆAkshareæ¥å£ï¼šcrypto_ohlcv_hist_minï¼‰\n",
    "# symbolå‚æ•°ï¼šBTC/USDTï¼›periodå‚æ•°ï¼š1åˆ†é’Ÿï¼ˆ1minï¼‰\n",
    "df = ak.crypto_ohlcv_hist_min(\n",
    "    symbol=\"BTC/USDT\",\n",
    "    period=\"1min\",\n",
    "    start_date=\"2017-01-01 00:00:00\",  # èµ·å§‹æ—¶é—´ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # ç»“æŸæ—¶é—´ä¸ºå½“å‰\n",
    ")\n",
    "\n",
    "# æ•°æ®æ¸…æ´—ï¼šä¿ç•™æ ¸å¿ƒå­—æ®µ+å»é‡\n",
    "df = df[['datetime', 'open', 'high', 'low', 'close', 'volume']].drop_duplicates(subset=['datetime'])\n",
    "\n",
    "# ä¿å­˜åˆ°a.csv\n",
    "df.to_csv('a.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# æ‰“å°ç»“æœä¿¡æ¯\n",
    "print(f\"âœ… æ•°æ®å·²ä¿å­˜åˆ°a.csvï¼\")\n",
    "print(f\"ğŸ“Š æ•°æ®æ€»é‡ï¼š{len(df)} æ¡1åˆ†é’ŸKçº¿\")\n",
    "print(f\"ğŸ•’ æ—¶é—´èŒƒå›´ï¼š{df['datetime'].min()} è‡³ {df['datetime'].max()}\")\n",
    "print(\"\\nå‰5æ¡æ•°æ®é¢„è§ˆï¼š\")\n",
    "print(df.head())"
   ],
   "id": "9d10ed57d5893f3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å–BTC/USDTæ—¥çº¿è¡Œæƒ…ï¼ˆå…¨çƒäº¤æ˜“æ‰€èšåˆæ•°æ®ï¼‰\n",
    "df = ak.crypto_global_spot_hist(\n",
    "    symbol=\"BTC\",\n",
    "    trade=\"USDT\",\n",
    "    start_date=\"2024-01-01\",  # èµ·å§‹æ—¶é—´\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\")  # ç»“æŸæ—¶é—´\n",
    ")\n",
    "\n",
    "# æ•°æ®æ¸…æ´—+ä¿å­˜åˆ°a.csv\n",
    "df = df[['date', 'open', 'high', 'low', 'close', 'volume']].drop_duplicates(subset=['date'])\n",
    "df.rename(columns={'date': 'datetime'}, inplace=True)  # ç»Ÿä¸€å­—æ®µå\n",
    "df.to_csv('a.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(f\"âœ… å·²ä¿å­˜{len(df)}æ¡BTC/USDTæ—¥çº¿æ•°æ®åˆ°a.csv\")\n",
    "print(f\"æ—¶é—´èŒƒå›´ï¼š{df['datetime'].min()} è‡³ {df['datetime'].max()}\")\n",
    "print(\"\\nå‰5æ¡æ•°æ®ï¼š\")\n",
    "print(df.head())"
   ],
   "id": "2df9ac44e8bc4b54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å–Binanceäº¤æ˜“æ‰€BTC/USDTè¿‘æœŸ1åˆ†é’Ÿè¡Œæƒ…ï¼ˆä»…æ”¯æŒè¿‘å‡ å¤©æ•°æ®ï¼‰\n",
    "df = ak.crypto_exchange_spot_minute(\n",
    "    exchange=\"binance\",\n",
    "    symbol=\"BTC/USDT\",\n",
    "    period=\"1åˆ†é’Ÿ\",\n",
    "    start_date=\"2024-12-01 00:00:00\",  # ä»…æ”¯æŒè¿‘æœŸï¼ˆå¦‚è¿‘1å‘¨ï¼‰ï¼Œæ›´æ—©æ•°æ®è·å–å¤±è´¥\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    ")\n",
    "\n",
    "# ä¿å­˜åˆ°a.csv\n",
    "df = df.drop_duplicates(subset=['datetime'])\n",
    "df.to_csv('a.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"âœ… å·²ä¿å­˜{len(df)}æ¡BTC/USDT 1åˆ†é’Ÿæ•°æ®åˆ°a.csv\")\n",
    "print(f\"æ—¶é—´èŒƒå›´ï¼š{df['datetime'].min()} è‡³ {df['datetime'].max()}\")"
   ],
   "id": "63ce2aad2e77fd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# æœ€æ–°ç‰ˆ Akshare ç¨³å®šçš„ BTC/USDT æ—¥çº¿æ¥å£\n",
    "df = ak.crypto_global_spot_hist(\n",
    "    symbol=\"BTC\",       # å¸ç§\n",
    "    trade=\"USDT\",       # äº¤æ˜“å¯¹\n",
    "    start_date=\"2024-01-01\",  # èµ·å§‹æ—¶é—´\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\")  # ç»“æŸæ—¶é—´\n",
    ")\n",
    "\n",
    "# æ¸…æ´—æ•°æ®å¹¶ä¿å­˜åˆ° a.csv\n",
    "df = df[['date', 'open', 'high', 'low', 'close', 'volume']].drop_duplicates()\n",
    "df.rename(columns={'date': 'datetime'}, inplace=True)  # ç»Ÿä¸€å­—æ®µå\n",
    "df.to_csv('a.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(f\"âœ… å·²ä¿å­˜ {len(df)} æ¡ BTC/USDT æ—¥çº¿æ•°æ®åˆ° a.csv\")\n",
    "print(f\"æ—¶é—´èŒƒå›´ï¼š{df['datetime'].min()} ~ {df['datetime'].max()}\")\n",
    "print(\"\\næ•°æ®é¢„è§ˆï¼š\")\n",
    "print(df.head())"
   ],
   "id": "229a341cd242bd42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å– BTC/USDT æ—¥çº¿åŸå§‹æ•°æ®ï¼ˆä¸åšå¤„ç†ï¼‰\n",
    "df = ak.crypto_global_spot_hist(\n",
    "    symbol=\"BTC\",\n",
    "    trade=\"USDT\",\n",
    "    start_date=\"2024-01-01\",\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\")\n",
    ")\n",
    "\n",
    "# åŸæ ·å­˜åˆ° a.csv\n",
    "df.to_csv(\"a.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"å·²ä¿å­˜ {len(df)} æ¡æ•°æ®åˆ° a.csv\")\n",
    "print(df.head())\n"
   ],
   "id": "d8a09a50add9a716",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pip install --upgrade akshare",
   "id": "84226c46b25c9ca8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å– BTC/USDT æ—¥çº¿åŸå§‹æ•°æ®ï¼ˆä¸åšå¤„ç†ï¼‰\n",
    "df = ak.crypto_global_spot_hist(\n",
    "    symbol=\"BTC\",\n",
    "    trade=\"USDT\",\n",
    "    start_date=\"2024-01-01\",\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\")\n",
    ")\n",
    "\n",
    "# åŸæ ·å­˜åˆ° a.csv\n",
    "df.to_csv(\"a.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"å·²ä¿å­˜ {len(df)} æ¡æ•°æ®åˆ° a.csv\")\n",
    "print(df.head())\n"
   ],
   "id": "5cf9e20e4895d255",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "\n",
    "# äº¤æ˜“æ‰€ï¼ˆæ— éœ€API Keyï¼‰\n",
    "exchange = ccxt.binance({\n",
    "    'enableRateLimit': True,\n",
    "    'timeout': 30000,\n",
    "})\n",
    "\n",
    "# è·å–æ—¥çº¿ï¼ˆ1dï¼‰\n",
    "data = exchange.fetch_ohlcv('BTC/USDT', timeframe='1d', limit=1000)\n",
    "\n",
    "# è½¬æˆ DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"\n",
    "])\n",
    "\n",
    "# æ—¶é—´æˆ³è½¬æ¢\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"timestamp\"], unit='ms')\n",
    "\n",
    "# ä¿å­˜ CSV\n",
    "df.to_csv(\"a.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"å·²ä¿å­˜ BTC/USDT æ—¥çº¿æ•°æ®åˆ° a.csv\")\n",
    "print(df.head())\n"
   ],
   "id": "8615a601e77bf278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "exchange = ccxt.binance({\n",
    "    'enableRateLimit': True,\n",
    "    'timeout': 30000,\n",
    "})\n",
    "\n",
    "symbol = 'BTC/USDT'\n",
    "timeframe = '1d'\n",
    "since = exchange.parse8601('2017-08-17T00:00:00Z')  # Binanceä¸Šçº¿BTC/USDTçš„è¿‘ä¼¼æ—¶é—´\n",
    "all_data = []\n",
    "\n",
    "while True:\n",
    "    print(f\"Fetching since {pd.to_datetime(since, unit='ms')}\")\n",
    "    data = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=1000)\n",
    "    if not data:\n",
    "        break\n",
    "    all_data += data\n",
    "    since = data[-1][0] + 24*60*60*1000  # ä¸‹ä¸€å¤©å¼€å§‹\n",
    "    time.sleep(exchange.rateLimit / 1000)  # é¿å…è§¦å‘é™é€Ÿ\n",
    "\n",
    "# è½¬æˆ DataFrame\n",
    "df = pd.DataFrame(all_data, columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"timestamp\"], unit='ms')\n",
    "\n",
    "# ä¿å­˜ CSV\n",
    "df.to_csv(\"a.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"å·²ä¿å­˜ {len(df)} æ¡ BTC/USDT æ—¥çº¿æ•°æ®åˆ° a.csv\")\n",
    "print(df.head())\n"
   ],
   "id": "7d7175c4e70112cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "\n",
    "# åˆå§‹åŒ– Binance äº¤æ˜“æ‰€ï¼ˆä»…è¡Œæƒ…ï¼Œæ— éœ€å¯†é’¥ï¼‰\n",
    "exchange = ccxt.binance({'enableRateLimit': True})\n",
    "\n",
    "# è·å–æœ€è¿‘ 1000 æ¡ BTC/USDT 1 åˆ†é’Ÿæ•°æ®ï¼ˆç§’çº§å®Œæˆï¼Œå¯æ”¹ limit æˆ–å¾ªç¯è·å–å…¨é‡ï¼‰\n",
    "ohlcv = exchange.fetch_ohlcv('BTC/USDT', '1m', limit=1000)\n",
    "\n",
    "# è½¬æ¢ä¸º DataFrame + å¤„ç†æ—¶é—´\n",
    "df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')  # æ¯«ç§’è½¬å¯è¯»æ—¶é—´\n",
    "\n",
    "# ä¿å­˜åˆ° a.csv\n",
    "df.to_csv('a.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(f\"âœ… å·²ä¿å­˜ {len(df)} æ¡ BTC/USDT 1 åˆ†é’Ÿæ•°æ®åˆ° a.csv\")\n",
    "print(f\"æ—¶é—´èŒƒå›´ï¼š{df['datetime'].min()} ~ {df['datetime'].max()}\")\n",
    "print(\"\\næ•°æ®é¢„è§ˆï¼š\")\n",
    "print(df.head())"
   ],
   "id": "95f7c17f336aa99b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# ====================== æ ¸å¿ƒé…ç½® ======================\n",
    "STOCK_CODE = \"600519\"  # è´µå·èŒ…å°è‚¡ç¥¨ä»£ç \n",
    "ADJUST_TYPE = \"qfq\"    # å¤æƒç±»å‹ï¼šqfq-å‰å¤æƒï¼ˆæ¨èï¼‰ï¼Œhfq-åå¤æƒï¼ŒNone-ä¸å¤æƒ\n",
    "\n",
    "# ====================== è·å–å…¨éƒ¨å†å²è¡Œæƒ… ======================\n",
    "# stock_zh_a_hist æ˜¯Akshareç¨³å®šæ¥å£ï¼Œæ”¯æŒæ‰€æœ‰Aè‚¡å†å²æ—¥çº¿æ•°æ®\n",
    "df = ak.stock_zh_a_hist(\n",
    "    symbol=STOCK_CODE,\n",
    "    period=\"daily\",       # æ—¥çº¿ï¼ˆå…¨éƒ¨å†å²ä»…æ”¯æŒæ—¥çº¿ï¼Œåˆ†é’Ÿçº§æ— å…¨é‡ï¼‰\n",
    "    start_date=\"2001-08-27\",  # èŒ…å°ä¸Šå¸‚æ—¶é—´ï¼ˆç¡®ä¿è·å–å…¨éƒ¨å†å²ï¼‰\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\"),  # ç»“æŸæ—¶é—´ä¸ºå½“å‰\n",
    "    adjust=ADJUST_TYPE    # å‰å¤æƒï¼ˆæ¶ˆé™¤é™¤æƒé™¤æ¯å½±å“ï¼Œåˆ†ææ›´å‡†ç¡®ï¼‰\n",
    ")\n",
    "\n",
    "# ====================== æ•°æ®æ¸…æ´—ï¼ˆå¯é€‰ï¼Œä¼˜åŒ–æ ¼å¼ï¼‰ ======================\n",
    "# ä¿ç•™æ ¸å¿ƒå­—æ®µ + å»é‡ + æ’åº\n",
    "df = df[[\"æ—¥æœŸ\", \"å¼€ç›˜\", \"æœ€é«˜\", \"æœ€ä½\", \"æ”¶ç›˜\", \"æˆäº¤é‡\", \"æˆäº¤é¢\"]].drop_duplicates(subset=[\"æ—¥æœŸ\"])\n",
    "df = df.sort_values(\"æ—¥æœŸ\").reset_index(drop=True)  # æŒ‰æ—¥æœŸæ­£åºæ’åˆ—\n",
    "\n",
    "# ====================== ä¿å­˜åˆ°a.csv ======================\n",
    "df.to_csv(\"a.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# ====================== æ‰“å°ç»“æœéªŒè¯ ======================\n",
    "print(f\"âœ… è´µå·èŒ…å°ï¼ˆ{STOCK_CODE}ï¼‰å…¨éƒ¨å†å²è¡Œæƒ…å·²ä¿å­˜åˆ°a.csv\")\n",
    "print(f\"ğŸ“Š æ•°æ®æ€»é‡ï¼š{len(df)} æ¡æ—¥çº¿ï¼ˆä¸Šå¸‚è‡³ä»Šï¼‰\")\n",
    "print(f\"ğŸ•’ æ—¶é—´èŒƒå›´ï¼š{df['æ—¥æœŸ'].min()} è‡³ {df['æ—¥æœŸ'].max()}\")\n",
    "print(\"\\nå‰5è¡Œæ•°æ®é¢„è§ˆï¼š\")\n",
    "print(df.head())"
   ],
   "id": "8cae656eaad6d237",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# ====================== æ ¸å¿ƒé…ç½® ======================\n",
    "STOCK_CODE = \"600519\"  # è´µå·èŒ…å°è‚¡ç¥¨ä»£ç \n",
    "ADJUST_TYPE = \"qfq\"    # å‰å¤æƒï¼ˆæ¨èï¼‰\n",
    "\n",
    "# ====================== è·å–å…¨éƒ¨å†å²è¡Œæƒ… ======================\n",
    "df = ak.stock_zh_a_hist(\n",
    "    symbol=STOCK_CODE,\n",
    "    period=\"daily\",\n",
    "    start_date=\"2001-08-27\",  # èŒ…å°ä¸Šå¸‚æ—¶é—´\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\"),\n",
    "    adjust=ADJUST_TYPE\n",
    ")\n",
    "\n",
    "# ====================== å…¼å®¹åˆ—åï¼ˆå…³é”®ï¼šç»Ÿä¸€ä¸­è‹±æ–‡åˆ—åï¼‰ ======================\n",
    "# å…ˆæ‰“å°å®é™…åˆ—åï¼ˆæ–¹ä¾¿æ’æŸ¥ï¼‰\n",
    "print(\"æ¥å£è¿”å›çš„å®é™…åˆ—åï¼š\", df.columns.tolist())\n",
    "\n",
    "# åˆ—åæ˜ å°„ï¼ˆè¦†ç›–ä¸­è‹±æ–‡ä¸¤ç§æƒ…å†µï¼‰\n",
    "col_mapping = {\n",
    "    'datetime': 'æ—¥æœŸ', 'date': 'æ—¥æœŸ',\n",
    "    'open': 'å¼€ç›˜', 'å¼€ç›˜ä»·': 'å¼€ç›˜',\n",
    "    'high': 'æœ€é«˜', 'æœ€é«˜ä»·': 'æœ€é«˜',\n",
    "    'low': 'æœ€ä½', 'æœ€ä½ä»·': 'æœ€ä½',\n",
    "    'close': 'æ”¶ç›˜', 'æ”¶ç›˜ä»·': 'æ”¶ç›˜',\n",
    "    'volume': 'æˆäº¤é‡',\n",
    "    'amount': 'æˆäº¤é¢', 'æˆäº¤é¢': 'æˆäº¤é¢'\n",
    "}\n",
    "# é‡å‘½ååˆ—ï¼ˆä¸ç®¡åŸåˆ—åæ˜¯è‹±æ–‡è¿˜æ˜¯ä¸­æ–‡ï¼Œéƒ½ç»Ÿä¸€ä¸ºä¸­æ–‡ï¼‰\n",
    "df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "# ====================== æ•°æ®æ¸…æ´— ======================\n",
    "# ç­›é€‰æ ¸å¿ƒåˆ—ï¼ˆç¡®ä¿åˆ—åå­˜åœ¨ï¼‰\n",
    "core_cols = [\"æ—¥æœŸ\", \"å¼€ç›˜\", \"æœ€é«˜\", \"æœ€ä½\", \"æ”¶ç›˜\", \"æˆäº¤é‡\", \"æˆäº¤é¢\"]\n",
    "# åªä¿ç•™å­˜åœ¨çš„åˆ—ï¼ˆé¿å…æ¼åˆ—æŠ¥é”™ï¼‰\n",
    "core_cols = [col for col in core_cols if col in df.columns]\n",
    "df = df[core_cols].drop_duplicates(subset=[\"æ—¥æœŸ\"])\n",
    "df = df.sort_values(\"æ—¥æœŸ\").reset_index(drop=True)\n",
    "\n",
    "# ====================== ä¿å­˜åˆ°a.csv ======================\n",
    "df.to_csv(\"a.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# ====================== éªŒè¯ç»“æœ ======================\n",
    "print(f\"\\nâœ… è´µå·èŒ…å°ï¼ˆ{STOCK_CODE}ï¼‰å…¨éƒ¨å†å²è¡Œæƒ…å·²ä¿å­˜åˆ°a.csv\")\n",
    "print(f\"ğŸ“Š æ•°æ®æ€»é‡ï¼š{len(df)} æ¡æ—¥çº¿\")\n",
    "print(f\"ğŸ•’ æ—¶é—´èŒƒå›´ï¼š{df['æ—¥æœŸ'].min()} è‡³ {df['æ—¥æœŸ'].max()}\")\n",
    "print(\"\\nå‰5è¡Œæ•°æ®é¢„è§ˆï¼š\")\n",
    "print(df.head())"
   ],
   "id": "4a59e9272b21aea4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# æ ¸å¿ƒé…ç½®\n",
    "STOCK_CODE = \"600519\"  # è´µå·èŒ…å°\n",
    "ADJUST_TYPE = \"qfq\"    # å‰å¤æƒ\n",
    "\n",
    "# 1. è·å–å…¨éƒ¨å†å²æ•°æ®ï¼ˆä¸ç­›é€‰åˆ—ï¼Œå…ˆæ‹¿åˆ°åŸå§‹æ•°æ®ï¼‰\n",
    "df = ak.stock_zh_a_hist(\n",
    "    symbol=STOCK_CODE,\n",
    "    period=\"daily\",\n",
    "    start_date=\"2001-08-27\",  # èŒ…å°ä¸Šå¸‚æ—¶é—´\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\"),\n",
    "    adjust=ADJUST_TYPE\n",
    ")\n",
    "\n",
    "# 2. æ‰“å°åŸå§‹æ•°æ®ä¿¡æ¯ï¼ˆæ–¹ä¾¿æ’æŸ¥ï¼Œå¯é€‰ï¼‰\n",
    "print(\"=== åŸå§‹æ•°æ®ä¿¡æ¯ ===\")\n",
    "print(f\"åŸå§‹åˆ—åï¼š{df.columns.tolist()}\")\n",
    "print(f\"åŸå§‹æ•°æ®å‰3è¡Œï¼š\\n{df.head(3)}\")\n",
    "\n",
    "# 3. å¼ºåˆ¶æŒ‰åˆ—é¡ºåºé‡å‘½åï¼ˆæ ¸å¿ƒï¼šä¸ç®¡åŸåˆ—åæ˜¯ä»€ä¹ˆï¼ŒæŒ‰å›ºå®šé¡ºåºèµ‹å€¼ä¸­æ–‡åˆ—åï¼‰\n",
    "# stock_zh_a_hist è¿”å›åˆ—çš„å›ºå®šé¡ºåºï¼šæ—¶é—´ã€å¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ã€æˆäº¤é‡ã€æˆäº¤é¢ï¼ˆå‰7åˆ—ï¼‰\n",
    "df_rename = df.iloc[:, :7].copy()  # åªå–å‰7åˆ—ï¼ˆæ ¸å¿ƒæ•°æ®åˆ—ï¼‰\n",
    "df_rename.columns = [\"æ—¥æœŸ\", \"å¼€ç›˜\", \"æœ€é«˜\", \"æœ€ä½\", \"æ”¶ç›˜\", \"æˆäº¤é‡\", \"æˆäº¤é¢\"]\n",
    "\n",
    "# 4. æ•°æ®æ¸…æ´—ï¼ˆå»é‡ã€æ’åºï¼‰\n",
    "df_rename = df_rename.drop_duplicates(subset=[\"æ—¥æœŸ\"])  # æŒ‰æ—¥æœŸå»é‡\n",
    "df_rename = df_rename.sort_values(\"æ—¥æœŸ\").reset_index(drop=True)  # æŒ‰æ—¥æœŸæ’åº\n",
    "\n",
    "# 5. ä¿å­˜åˆ°a.csv\n",
    "df_rename.to_csv(\"a.csv\", index=False, encoding=\"utf-8-sig\")  # utf-8-sigè§£å†³Excelä¹±ç \n",
    "\n",
    "# 6. éªŒè¯ç»“æœ\n",
    "print(\"\\n=== ä¿å­˜ç»“æœ ===\")\n",
    "print(f\"âœ… è´µå·èŒ…å°å…¨éƒ¨å†å²è¡Œæƒ…å·²ä¿å­˜åˆ°a.csv\")\n",
    "print(f\"æ•°æ®æ€»é‡ï¼š{len(df_rename)} æ¡æ—¥çº¿\")\n",
    "print(f\"æ—¶é—´èŒƒå›´ï¼š{df_rename['æ—¥æœŸ'].min()} è‡³ {df_rename['æ—¥æœŸ'].max()}\")\n",
    "print(\"\\næœ€ç»ˆæ•°æ®å‰5è¡Œï¼š\")\n",
    "print(df_rename.head())"
   ],
   "id": "20e97c5baf5ad1a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# ä»…ä¿ç•™æ ¸å¿ƒé€»è¾‘ï¼šè·å–èŒ…å°å…¨éƒ¨å†å²è¡Œæƒ… â†’ ç›´æ¥ä¿å­˜åŸå§‹æ•°æ®åˆ°a.csv\n",
    "try:\n",
    "    # 1. è·å–åŸå§‹æ•°æ®ï¼ˆä¸åšä»»ä½•åˆ—ç­›é€‰ã€é‡å‘½åï¼‰\n",
    "    df = ak.stock_zh_a_hist(\n",
    "        symbol=\"600519\",       # è´µå·èŒ…å°è‚¡ç¥¨ä»£ç \n",
    "        period=\"daily\",         # æ—¥çº¿ï¼ˆå…¨éƒ¨å†å²ä»…æ”¯æŒæ—¥çº¿ï¼‰\n",
    "        start_date=\"2001-08-27\",# èŒ…å°ä¸Šå¸‚æ—¶é—´ï¼Œç¡®ä¿å…¨é‡\n",
    "        end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\"),\n",
    "        adjust=\"qfq\"            # å‰å¤æƒï¼ˆä¸æƒ³åŠ å¯ä»¥åˆ ï¼Œæ”¹ä¸ºadjust=Noneï¼‰\n",
    "    )\n",
    "\n",
    "    # 2. æ‰“å°åŸå§‹æ•°æ®ä¿¡æ¯ï¼ˆæ–¹ä¾¿ä½ æ ¸å¯¹ï¼‰\n",
    "    print(\"=== åŸå§‹æ•°æ®åŸºæœ¬ä¿¡æ¯ ===\")\n",
    "    print(f\"æ•°æ®æ˜¯å¦ä¸ºç©ºï¼š{df.empty}\")\n",
    "    print(f\"æ•°æ®æ€»è¡Œæ•°ï¼š{len(df)}\")\n",
    "    print(f\"åŸå§‹åˆ—åï¼š{df.columns.tolist()}\")\n",
    "    print(\"\\nåŸå§‹æ•°æ®å‰3è¡Œï¼š\")\n",
    "    print(df.head(3))\n",
    "\n",
    "    # 3. ç›´æ¥ä¿å­˜åŸå§‹æ•°æ®åˆ°a.csvï¼ˆä¸ä¿®æ”¹ä»»ä½•å†…å®¹ï¼‰\n",
    "    df.to_csv(r\"C:\\Users\\wangd\\Desktop\\a.csv\", index=False, encoding=\"utf-8-sig\")  # utf-8-sigè§£å†³Excelä¹±ç \n",
    "    print(\"\\nâœ… æ•°æ®å·²ç›´æ¥ä¿å­˜åˆ°a.csvï¼ˆæœªåšä»»ä½•ä¿®æ”¹ï¼‰\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ è¿è¡Œå‡ºé”™ï¼š{str(e)}\")"
   ],
   "id": "60438d9b61160e63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# æ ¸å¿ƒï¼šèŒ…å°æ˜¯æ²ªå¸‚è‚¡ç¥¨ï¼Œå¿…é¡»æŒ‡å®šmarket=\"sh\"ï¼Œç”¨ä¸œæ–¹è´¢å¯Œæœ€ç¨³å®šçš„æ¥å£\n",
    "df = ak.stock_hist_em(\n",
    "    symbol=\"600519\",       # èŒ…å°è‚¡ç¥¨ä»£ç \n",
    "    period=\"daily\",         # æ—¥çº¿ï¼ˆå…¨é‡å†å²ï¼‰\n",
    "    start_date=\"2001-08-27\",# èŒ…å°ä¸Šå¸‚æ—¶é—´\n",
    "    end_date=pd.Timestamp.now().strftime(\"%Y-%m-%d\"),\n",
    "    adjust=\"qfq\"            # å‰å¤æƒï¼ˆä¸æƒ³ç”¨å°±æ”¹adjust=\"none\"ï¼‰\n",
    ")\n",
    "\n",
    "# ç›´æ¥ä¿å­˜åŸå§‹æ•°æ®ï¼Œä¸åšä»»ä½•ä¿®æ”¹\n",
    "df.to_csv(r\"C:\\Users\\wangd\\Desktop\\a.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# æ‰“å°éªŒè¯ï¼ˆèƒ½çœ‹åˆ°æ•°æ®å°±è¯´æ˜æˆäº†ï¼‰\n",
    "print(f\"âœ… æˆåŠŸè·å–ï¼æ•°æ®æ€»è¡Œæ•°ï¼š{len(df)}\")\n",
    "print(f\"âœ… æ—¶é—´èŒƒå›´ï¼š{df['æ—¥æœŸ'].min()} è‡³ {df['æ—¥æœŸ'].max()}\")\n",
    "print(\"\\nå‰5è¡Œæ•°æ®ï¼š\")\n",
    "print(df[[\"æ—¥æœŸ\", \"å¼€ç›˜ä»·\", \"æœ€é«˜ä»·\", \"æœ€ä½ä»·\", \"æ”¶ç›˜ä»·\", \"æˆäº¤é‡\"]].head())"
   ],
   "id": "e56654cf65afde1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "70b2eefe32560212",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å–èŒ…å°å†å²æ—¥çº¿æ•°æ®\n",
    "stock_zh_a_daily_df = ak.stock_zh_a_daily(symbol=\"sh600519\", adjust=\"\")\n",
    "\n",
    "# ä¿å­˜åˆ°a.csvæ–‡ä»¶\n",
    "stock_zh_a_daily_df.to_csv(r\"C:\\Users\\wangd\\Desktop\\a.csv\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"èŒ…å°å†å²æ—¥çº¿æ•°æ®å·²ä¿å­˜åˆ°a.csvæ–‡ä»¶ä¸­\")"
   ],
   "id": "29145392a700eb6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:46:26.744761Z",
     "start_time": "2025-12-04T14:46:26.380143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å–ç‰ç±³æœŸè´§ä¸»åŠ›åˆçº¦å†å²è¡Œæƒ…æ•°æ®ï¼ˆä¸€åˆ†é’Ÿçº§åˆ«ï¼‰\n",
    "try:\n",
    "    # è·å–ç‰ç±³æœŸè´§ä¸»åŠ›åˆçº¦ä»£ç \n",
    "    corn_main_contract = \"C\"  # å¤§è¿å•†å“äº¤æ˜“æ‰€ç‰ç±³æœŸè´§ä»£ç \n",
    "\n",
    "    # è·å–å†å²åˆ†é’Ÿçº§åˆ«æ•°æ®\n",
    "    corn_futures_min = ak.futures_zh_minute_sina(symbol=\"C0\", period=\"1\")\n",
    "\n",
    "    # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„\n",
    "    save_path = r\"C:\\Users\\wangd\\Desktop\\yumi.csv\"\n",
    "    corn_futures_min.to_csv(save_path, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"ç‰ç±³æœŸè´§å†å²è¡Œæƒ…æ•°æ®å·²ä¿å­˜åˆ°{save_path}æ–‡ä»¶ä¸­\")\n",
    "    print(f\"å…±è·å–äº†{len(corn_futures_min)}æ¡æ•°æ®è®°å½•\")\n",
    "    print(\"æ•°æ®é¢„è§ˆï¼š\")\n",
    "    print(corn_futures_min.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"è·å–ç‰ç±³æœŸè´§æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}\")\n",
    "\n",
    "    # å¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„ç‰ç±³æœŸè´§åˆçº¦ä»£ç \n",
    "    try:\n",
    "        # å°è¯•è·å–å½“å‰æ´»è·ƒçš„ç‰ç±³æœŸè´§åˆçº¦\n",
    "        corn_futures_list = ak.futures_spot_price_daily(trade_date=\"20241101\", symbol=\"ç‰ç±³\")\n",
    "        print(\"å¯è·å–çš„ç‰ç±³æœŸè´§åˆçº¦åˆ—è¡¨ï¼š\")\n",
    "        print(corn_futures_list)\n",
    "    except Exception as e2:\n",
    "        print(f\"å¤‡é€‰æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "723d2a89d25adfe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰ç±³æœŸè´§å†å²è¡Œæƒ…æ•°æ®å·²ä¿å­˜åˆ°C:\\Users\\wangd\\Desktop\\yumi.csvæ–‡ä»¶ä¸­\n",
      "å…±è·å–äº†1023æ¡æ•°æ®è®°å½•\n",
      "æ•°æ®é¢„è§ˆï¼š\n",
      "              datetime    open    high     low   close  volume    hold\n",
      "0  2025-12-01 23:00:00  2243.0  2244.0  2242.0  2243.0    1906  950195\n",
      "1  2025-12-02 09:01:00  2245.0  2246.0  2243.0  2246.0   11106  950470\n",
      "2  2025-12-02 09:02:00  2246.0  2250.0  2245.0  2250.0   15733  952337\n",
      "3  2025-12-02 09:03:00  2249.0  2249.0  2246.0  2247.0    9527  954480\n",
      "4  2025-12-02 09:04:00  2247.0  2247.0  2245.0  2246.0    3060  955418\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:47:44.613924Z",
     "start_time": "2025-12-04T14:47:44.046329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å–ç‰ç±³æœŸè´§ä¸»åŠ›åˆçº¦å†å²è¡Œæƒ…æ•°æ®ï¼ˆä¸€åˆ†é’Ÿçº§åˆ«ï¼‰\n",
    "try:\n",
    "    # è·å–ç‰ç±³æœŸè´§ä¸»åŠ›åˆçº¦å†å²æ•°æ®\n",
    "    # é¦–å…ˆè·å–å¯ç”¨çš„æœŸè´§åˆçº¦åˆ—è¡¨\n",
    "    corn_futures_list = ak.match_main_contract(symbol=\"C\")\n",
    "    print(f\"å½“å‰ç‰ç±³æœŸè´§ä¸»åŠ›åˆçº¦: {corn_futures_list}\")\n",
    "\n",
    "    # è·å–ä¸»åŠ›åˆçº¦çš„ä¸€åˆ†é’Ÿçº§åˆ«æ•°æ®\n",
    "    corn_futures_min = ak.futures_zh_minute_sina(symbol= corn_futures_list, period=\"1\")\n",
    "\n",
    "    # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„\n",
    "    save_path = r\"C:\\Users\\wangd\\Desktop\\yumi.csv\"\n",
    "    corn_futures_min.to_csv(save_path, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"ç‰ç±³æœŸè´§å†å²è¡Œæƒ…æ•°æ®å·²ä¿å­˜åˆ°{save_path}æ–‡ä»¶ä¸­\")\n",
    "    print(f\"å…±è·å–äº†{len(corn_futures_min)}æ¡æ•°æ®è®°å½•\")\n",
    "\n",
    "    if not corn_futures_min.empty:\n",
    "        print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {corn_futures_min.index.min()} åˆ° {corn_futures_min.index.max()}\")\n",
    "\n",
    "    print(\"æ•°æ®é¢„è§ˆï¼š\")\n",
    "    print(corn_futures_min.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"è·å–ç‰ç±³æœŸè´§æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}\")\n",
    "\n",
    "    # å¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼Œå°è¯•è·å–æ—¥çº¿æ•°æ®ä½œä¸ºå¤‡é€‰\n",
    "    try:\n",
    "        print(\"å°è¯•è·å–ç‰ç±³æœŸè´§æ—¥çº¿æ•°æ®...\")\n",
    "        # è·å–ç‰ç±³æœŸè´§æ—¥çº¿æ•°æ®\n",
    "        corn_futures_daily = ak.futures_main_sina(symbol=\"C\")\n",
    "\n",
    "        # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„\n",
    "        save_path = r\"C:\\Users\\wangd\\Desktop\\yumi.csv\"\n",
    "        corn_futures_daily.to_csv(save_path, encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"ç‰ç±³æœŸè´§æ—¥çº¿æ•°æ®å·²ä¿å­˜åˆ°{save_path}æ–‡ä»¶ä¸­\")\n",
    "        print(f\"å…±è·å–äº†{len(corn_futures_daily)}æ¡æ•°æ®è®°å½•\")\n",
    "\n",
    "        if not corn_futures_daily.empty:\n",
    "            print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {corn_futures_daily.index.min()} åˆ° {corn_futures_daily.index.max()}\")\n",
    "\n",
    "        print(\"æ•°æ®é¢„è§ˆï¼š\")\n",
    "        print(corn_futures_daily.head())\n",
    "\n",
    "    except Exception as e2:\n",
    "        print(f\"å¤‡é€‰æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}\")\n",
    "        print(\"è¯·ç¡®è®¤akshareç‰ˆæœ¬æ˜¯å¦ä¸ºæœ€æ–°ï¼Œæˆ–è€…ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "d3ed7903724ba07b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è·å–ç‰ç±³æœŸè´§æ•°æ®æ—¶å‡ºç°é”™è¯¯: 'NoneType' object has no attribute 'iloc'\n",
      "å°è¯•è·å–ç‰ç±³æœŸè´§æ—¥çº¿æ•°æ®...\n",
      "å¤‡é€‰æ–¹æ³•ä¹Ÿå¤±è´¥: Expected object or value\n",
      "è¯·ç¡®è®¤akshareç‰ˆæœ¬æ˜¯å¦ä¸ºæœ€æ–°ï¼Œæˆ–è€…ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:48:50.081306Z",
     "start_time": "2025-12-04T14:48:49.623500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å–ç‰ç±³æœŸè´§ä¸»åŠ›åˆçº¦å†å²è¡Œæƒ…æ•°æ®ï¼ˆå°æ—¶çº§åˆ«ï¼‰\n",
    "try:\n",
    "    print(\"æ­£åœ¨è·å–ç‰ç±³æœŸè´§å°æ—¶çº¿æ•°æ®...\")\n",
    "\n",
    "    # è·å–æœŸè´§ä¸»åŠ›åˆçº¦ä¿¡æ¯\n",
    "    corn_symbol = \"C0\"  # å¤§è¿å•†å“äº¤æ˜“æ‰€ç‰ç±³ä¸»åŠ›åˆçº¦\n",
    "\n",
    "    # å°è¯•è·å–å°æ—¶æ•°æ®\n",
    "    try:\n",
    "        corn_futures_hour = ak.futures_zh_minute_sina(symbol=corn_symbol, period=\"60\")\n",
    "        if corn_futures_hour is not None and not corn_futures_hour.empty:\n",
    "            data_type = \"å°æ—¶\"\n",
    "            save_data = corn_futures_hour\n",
    "        else:\n",
    "            print(\"å°æ—¶æ•°æ®è·å–å¤±è´¥ï¼Œå°è¯•è·å–æ—¥çº¿æ•°æ®...\")\n",
    "            # è·å–ç‰ç±³æœŸè´§æ—¥çº¿æ•°æ®ä½œä¸ºå¤‡é€‰\n",
    "            corn_futures_daily = ak.futures_main_sina(symbol=\"C\")\n",
    "            if corn_futures_daily is not None and not corn_futures_daily.empty:\n",
    "                data_type = \"æ—¥çº¿\"\n",
    "                save_data = corn_futures_daily\n",
    "            else:\n",
    "                raise Exception(\"å°æ—¶å’Œæ—¥çº¿æ•°æ®éƒ½è·å–å¤±è´¥\")\n",
    "    except Exception as e:\n",
    "        print(f\"å°æ—¶æ•°æ®è·å–å¼‚å¸¸: {e}\")\n",
    "        print(\"å°è¯•è·å–å†å²æ—¥çº¿æ•°æ®...\")\n",
    "        # å°è¯•è·å–å†å²æ•°æ®\n",
    "        corn_futures_hist = ak.futures_hist(symbol=\"C\", period=\"daily\", start_date=\"20200101\", end_date=\"20241204\")\n",
    "        if corn_futures_hist is not None and not corn_futures_hist.empty:\n",
    "            data_type = \"å†å²æ—¥çº¿\"\n",
    "            save_data = corn_futures_hist\n",
    "        else:\n",
    "            raise Exception(\"æ‰€æœ‰æ•°æ®è·å–æ–¹æ³•éƒ½å¤±è´¥\")\n",
    "\n",
    "    # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„\n",
    "    save_path = r\"C:\\Users\\wangd\\Desktop\\yumi.csv\"\n",
    "    save_data.to_csv(save_path, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"ç‰ç±³æœŸè´§{data_type}è¡Œæƒ…æ•°æ®å·²ä¿å­˜åˆ°{save_path}æ–‡ä»¶ä¸­\")\n",
    "    print(f\"å…±è·å–äº†{len(save_data)}æ¡æ•°æ®è®°å½•\")\n",
    "\n",
    "    if not save_data.empty:\n",
    "        if 'date' in save_data.columns:\n",
    "            print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {save_data['date'].min()} åˆ° {save_data['date'].max()}\")\n",
    "        elif 'datetime' in save_data.columns:\n",
    "            print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {save_data['datetime'].min()} åˆ° {save_data['datetime'].max()}\")\n",
    "        else:\n",
    "            print(\"æ•°æ®æ—¶é—´èŒƒå›´: æ— æ³•ç¡®å®šæ—¶é—´åˆ—\")\n",
    "\n",
    "    print(\"æ•°æ®é¢„è§ˆï¼š\")\n",
    "    print(save_data.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"è·å–ç‰ç±³æœŸè´§æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}\")\n",
    "    print(\"è¯·ç¡®è®¤:\")\n",
    "    print(\"1. akshareç‰ˆæœ¬æ˜¯å¦ä¸ºæœ€æ–° (pip install akshare --upgrade)\")\n",
    "    print(\"2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")\n",
    "    print(\"3. æœŸè´§äº¤æ˜“æ—¶æ®µå†…è®¿é—®å¯èƒ½æ›´ç¨³å®š\")\n",
    "\n",
    "    # æä¾›ä¸€ä¸ªç©ºçš„CSVæ–‡ä»¶ä½œä¸ºå ä½ç¬¦\n",
    "    empty_df = pd.DataFrame(columns=['datetime', 'open', 'high', 'low', 'close', 'volume', 'symbol'])\n",
    "    empty_df.to_csv(r\"C:\\Users\\wangd\\Desktop\\yumi.csv\", encoding=\"utf-8\")\n",
    "    print(f\"å·²åˆ›å»ºç©ºçš„CSVæ–‡ä»¶ä½œä¸ºå ä½ç¬¦: C:\\\\Users\\\\wangd\\\\Desktop\\\\yumi.csv\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "629f48f509e39040",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è·å–ç‰ç±³æœŸè´§å°æ—¶çº¿æ•°æ®...\n",
      "ç‰ç±³æœŸè´§å°æ—¶è¡Œæƒ…æ•°æ®å·²ä¿å­˜åˆ°C:\\Users\\wangd\\Desktop\\yumi.csvæ–‡ä»¶ä¸­\n",
      "å…±è·å–äº†1023æ¡æ•°æ®è®°å½•\n",
      "æ•°æ®æ—¶é—´èŒƒå›´: 2025-03-25 11:15:00 åˆ° 2025-12-04 23:00:00\n",
      "æ•°æ®é¢„è§ˆï¼š\n",
      "              datetime    open    high     low   close  volume     hold\n",
      "0  2025-03-25 11:15:00  2274.0  2276.0  2271.0  2274.0   42322  1234928\n",
      "1  2025-03-25 14:15:00  2274.0  2275.0  2270.0  2272.0   46945  1229160\n",
      "2  2025-03-25 15:00:00  2272.0  2275.0  2271.0  2271.0   27538  1223148\n",
      "3  2025-03-25 22:00:00  2269.0  2277.0  2268.0  2273.0   96042  1228528\n",
      "4  2025-03-25 23:00:00  2274.0  2276.0  2272.0  2273.0   35456  1225479\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:50:33.697358Z",
     "start_time": "2025-12-04T14:50:33.139565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å–ç‰ç±³æœŸè´§ä¸»åŠ›åˆçº¦å†å²è¡Œæƒ…æ•°æ®ï¼ˆå®Œæ•´å†å²ï¼‰\n",
    "try:\n",
    "    print(\"æ­£åœ¨è·å–ç‰ç±³æœŸè´§å†å²æ•°æ®...\")\n",
    "\n",
    "    # è·å–å†å²æœŸè´§æ•°æ® - å°è¯•ä¸åŒçš„æ–¹æ³•è·å–å®Œæ•´å†å²æ•°æ®\n",
    "    corn_symbols = [\"C\", \"C0\", \"C88\"]  # ä¸åŒå¯èƒ½çš„ç‰ç±³æœŸè´§åˆçº¦ä»£ç \n",
    "\n",
    "    save_data = None\n",
    "    data_type = \"\"\n",
    "\n",
    "    # æ–¹æ³•1: å°è¯•ä½¿ç”¨futures_histè·å–å†å²æ•°æ®\n",
    "    try:\n",
    "        print(\"å°è¯•ä½¿ç”¨futures_histè·å–å†å²æ•°æ®...\")\n",
    "        corn_futures_hist = ak.futures_hist(symbol=\"C\", period=\"daily\", start_date=\"20100101\", end_date=\"20241204\")\n",
    "        if corn_futures_hist is not None and not corn_futures_hist.empty:\n",
    "            data_type = \"å†å²æ—¥çº¿(2010è‡³ä»Š)\"\n",
    "            save_data = corn_futures_hist\n",
    "            print(f\"æˆåŠŸè·å–{len(save_data)}æ¡å†å²æ•°æ®\")\n",
    "    except Exception as e1:\n",
    "        print(f\"futures_histæ–¹æ³•å¤±è´¥: {e1}\")\n",
    "\n",
    "    # å¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•æ–¹æ³•2\n",
    "    if save_data is None or save_data.empty:\n",
    "        try:\n",
    "            print(\"å°è¯•ä½¿ç”¨futures_main_sinaè·å–æ•°æ®...\")\n",
    "            corn_futures_main = ak.futures_main_sina(symbol=\"C\")\n",
    "            if corn_futures_main is not None and not corn_futures_main.empty:\n",
    "                data_type = \"ä¸»åŠ›åˆçº¦æ—¥çº¿\"\n",
    "                save_data = corn_futures_main\n",
    "                print(f\"æˆåŠŸè·å–{len(save_data)}æ¡ä¸»åŠ›åˆçº¦æ•°æ®\")\n",
    "        except Exception as e2:\n",
    "            print(f\"futures_main_sinaæ–¹æ³•å¤±è´¥: {e2}\")\n",
    "\n",
    "    # å¦‚æœå‰ä¸¤ç§æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•æ–¹æ³•3\n",
    "    if save_data is None or save_data.empty:\n",
    "        try:\n",
    "            print(\"å°è¯•è·å–æ‰€æœ‰æœŸè´§å“ç§ä¿¡æ¯...\")\n",
    "            futures_symbol = ak.futures_symbol_table(symbol=\"å¤§è¿å•†å“äº¤æ˜“æ‰€\")\n",
    "            corn_related = futures_symbol[futures_symbol['variety'].str.contains('ç‰ç±³', na=False)]\n",
    "            print(\"æ‰¾åˆ°çš„ç‰ç±³ç›¸å…³æœŸè´§å“ç§ï¼š\")\n",
    "            print(corn_related)\n",
    "\n",
    "            # å°è¯•è·å–ç‰¹å®šå†å²åˆçº¦\n",
    "            corn_futures_list = ak.futures_spot_price_daily(trade_date=\"20241101\", symbol=\"ç‰ç±³\")\n",
    "            if corn_futures_list is not None:\n",
    "                print(\"ç°è´§ä»·æ ¼æ•°æ®ï¼š\")\n",
    "                print(corn_futures_list)\n",
    "        except Exception as e3:\n",
    "            print(f\"å¤‡é€‰æ–¹æ³•å¤±è´¥: {e3}\")\n",
    "\n",
    "    if save_data is not None and not save_data.empty:\n",
    "        # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„\n",
    "        save_path = r\"C:\\Users\\wangd\\Desktop\\yumi.csv\"\n",
    "        save_data.to_csv(save_path, encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"ç‰ç±³æœŸè´§{data_type}è¡Œæƒ…æ•°æ®å·²ä¿å­˜åˆ°{save_path}æ–‡ä»¶ä¸­\")\n",
    "        print(f\"å…±è·å–äº†{len(save_data)}æ¡æ•°æ®è®°å½•\")\n",
    "\n",
    "        if not save_data.empty:\n",
    "            if 'date' in save_data.columns:\n",
    "                print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {save_data['date'].min()} åˆ° {save_data['date'].max()}\")\n",
    "            elif 'datetime' in save_data.columns:\n",
    "                print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {save_data['datetime'].min()} åˆ° {save_data['datetime'].max()}\")\n",
    "            else:\n",
    "                # å°è¯•è·å–ç´¢å¼•çš„æ—¶é—´èŒƒå›´\n",
    "                if pd.api.types.is_datetime64_any_dtype(save_data.index):\n",
    "                    print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {save_data.index.min()} åˆ° {save_data.index.max()}\")\n",
    "                else:\n",
    "                    print(\"æ•°æ®æ—¶é—´èŒƒå›´: æ— æ³•ç¡®å®šæ—¶é—´åˆ—\")\n",
    "\n",
    "        print(\"æ•°æ®é¢„è§ˆï¼š\")\n",
    "        print(save_data.head(10))\n",
    "        print(\"æ•°æ®å°¾éƒ¨é¢„è§ˆï¼š\")\n",
    "        print(save_data.tail(10))\n",
    "    else:\n",
    "        print(\"æ‰€æœ‰æ–¹æ³•éƒ½æœªèƒ½è·å–åˆ°æ•°æ®ï¼Œåˆ›å»ºç©ºæ–‡ä»¶\")\n",
    "        # åˆ›å»ºåŒ…å«åŸºæœ¬åˆ—çš„ç©ºæ•°æ®æ¡†\n",
    "        empty_df = pd.DataFrame(columns=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol'])\n",
    "        empty_df.to_csv(r\"C:\\Users\\wangd\\Desktop\\yumi.csv\", encoding=\"utf-8\")\n",
    "        print(f\"å·²åˆ›å»ºç©ºçš„CSVæ–‡ä»¶: C:\\\\Users\\\\wangd\\\\Desktop\\\\yumi.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"è·å–ç‰ç±³æœŸè´§æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}\")\n",
    "    print(\"è¯·ç¡®è®¤:\")\n",
    "    print(\"1. akshareç‰ˆæœ¬æ˜¯å¦ä¸ºæœ€æ–° (pip install akshare --upgrade)\")\n",
    "    print(\"2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")\n",
    "    print(\"3. æœŸè´§äº¤æ˜“æ—¶æ®µå†…è®¿é—®å¯èƒ½æ›´ç¨³å®š\")\n",
    "\n",
    "    # åˆ›å»ºç©ºæ–‡ä»¶ä½œä¸ºå ä½ç¬¦\n",
    "    empty_df = pd.DataFrame(columns=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol'])\n",
    "    empty_df.to_csv(r\"C:\\Users\\wangd\\Desktop\\yumi.csv\", encoding=\"utf-8\")\n",
    "    print(f\"å·²åˆ›å»ºç©ºçš„CSVæ–‡ä»¶ä½œä¸ºå ä½ç¬¦: C:\\\\Users\\\\wangd\\\\Desktop\\\\yumi.csv\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "3fbb20b86f3ed5d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è·å–ç‰ç±³æœŸè´§å†å²æ•°æ®...\n",
      "å°è¯•ä½¿ç”¨futures_histè·å–å†å²æ•°æ®...\n",
      "futures_histæ–¹æ³•å¤±è´¥: module 'akshare' has no attribute 'futures_hist'\n",
      "å°è¯•ä½¿ç”¨futures_main_sinaè·å–æ•°æ®...\n",
      "futures_main_sinaæ–¹æ³•å¤±è´¥: Expected object or value\n",
      "å°è¯•è·å–æ‰€æœ‰æœŸè´§å“ç§ä¿¡æ¯...\n",
      "å¤‡é€‰æ–¹æ³•å¤±è´¥: module 'akshare' has no attribute 'futures_symbol_table'\n",
      "æ‰€æœ‰æ–¹æ³•éƒ½æœªèƒ½è·å–åˆ°æ•°æ®ï¼Œåˆ›å»ºç©ºæ–‡ä»¶\n",
      "è·å–ç‰ç±³æœŸè´§æ•°æ®æ—¶å‡ºç°é”™è¯¯: [Errno 13] Permission denied: 'C:\\\\Users\\\\wangd\\\\Desktop\\\\yumi.csv'\n",
      "è¯·ç¡®è®¤:\n",
      "1. akshareç‰ˆæœ¬æ˜¯å¦ä¸ºæœ€æ–° (pip install akshare --upgrade)\n",
      "2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n",
      "3. æœŸè´§äº¤æ˜“æ—¶æ®µå†…è®¿é—®å¯èƒ½æ›´ç¨³å®š\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\wangd\\\\Desktop\\\\yumi.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPermissionError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 82\u001B[39m\n\u001B[32m     81\u001B[39m empty_df = pd.DataFrame(columns=[\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mopen\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mhigh\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mlow\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mclose\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mvolume\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33msymbol\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m---> \u001B[39m\u001B[32m82\u001B[39m \u001B[43mempty_df\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mC:\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mUsers\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mwangd\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mDesktop\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43myumi.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     83\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33må·²åˆ›å»ºç©ºçš„CSVæ–‡ä»¶: C:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[33mUsers\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[33mwangd\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[33mDesktop\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[33myumi.csv\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[39m, in \u001B[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    328\u001B[39m     warnings.warn(\n\u001B[32m    329\u001B[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001B[32m    330\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m    331\u001B[39m         stacklevel=find_stack_level(),\n\u001B[32m    332\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m333\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001B[39m, in \u001B[36mNDFrame.to_csv\u001B[39m\u001B[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[39m\n\u001B[32m   3977\u001B[39m formatter = DataFrameFormatter(\n\u001B[32m   3978\u001B[39m     frame=df,\n\u001B[32m   3979\u001B[39m     header=header,\n\u001B[32m   (...)\u001B[39m\u001B[32m   3983\u001B[39m     decimal=decimal,\n\u001B[32m   3984\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m3986\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3987\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3988\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3989\u001B[39m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[43m=\u001B[49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3990\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3991\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3992\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3993\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3994\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3995\u001B[39m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3996\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3997\u001B[39m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3998\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3999\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4000\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4001\u001B[39m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4002\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4003\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001B[39m, in \u001B[36mDataFrameRenderer.to_csv\u001B[39m\u001B[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[39m\n\u001B[32m    995\u001B[39m csv_formatter = CSVFormatter(\n\u001B[32m    996\u001B[39m     path_or_buf=path_or_buf,\n\u001B[32m    997\u001B[39m     lineterminator=lineterminator,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1012\u001B[39m     formatter=\u001B[38;5;28mself\u001B[39m.fmt,\n\u001B[32m   1013\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m \u001B[43mcsv_formatter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001B[39m, in \u001B[36mCSVFormatter.save\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    250\u001B[39m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    256\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    257\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    258\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[32m    259\u001B[39m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[32m    260\u001B[39m     \u001B[38;5;28mself\u001B[39m.writer = csvlib.writer(\n\u001B[32m    261\u001B[39m         handles.handle,\n\u001B[32m    262\u001B[39m         lineterminator=\u001B[38;5;28mself\u001B[39m.lineterminator,\n\u001B[32m   (...)\u001B[39m\u001B[32m    267\u001B[39m         quotechar=\u001B[38;5;28mself\u001B[39m.quotechar,\n\u001B[32m    268\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    871\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m     \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m     handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m        \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m     \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n",
      "\u001B[31mPermissionError\u001B[39m: [Errno 13] Permission denied: 'C:\\\\Users\\\\wangd\\\\Desktop\\\\yumi.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mPermissionError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 94\u001B[39m\n\u001B[32m     92\u001B[39m \u001B[38;5;66;03m# åˆ›å»ºç©ºæ–‡ä»¶ä½œä¸ºå ä½ç¬¦\u001B[39;00m\n\u001B[32m     93\u001B[39m empty_df = pd.DataFrame(columns=[\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mopen\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mhigh\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mlow\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mclose\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mvolume\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33msymbol\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m \u001B[43mempty_df\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mC:\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mUsers\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mwangd\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mDesktop\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43myumi.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     95\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33må·²åˆ›å»ºç©ºçš„CSVæ–‡ä»¶ä½œä¸ºå ä½ç¬¦: C:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[33mUsers\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[33mwangd\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[33mDesktop\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[33myumi.csv\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[39m, in \u001B[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) > num_allow_args:\n\u001B[32m    328\u001B[39m     warnings.warn(\n\u001B[32m    329\u001B[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001B[32m    330\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m    331\u001B[39m         stacklevel=find_stack_level(),\n\u001B[32m    332\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m333\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001B[39m, in \u001B[36mNDFrame.to_csv\u001B[39m\u001B[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[39m\n\u001B[32m   3975\u001B[39m df = \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.to_frame()\n\u001B[32m   3977\u001B[39m formatter = DataFrameFormatter(\n\u001B[32m   3978\u001B[39m     frame=df,\n\u001B[32m   3979\u001B[39m     header=header,\n\u001B[32m   (...)\u001B[39m\u001B[32m   3983\u001B[39m     decimal=decimal,\n\u001B[32m   3984\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m3986\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3987\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3988\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3989\u001B[39m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[43m=\u001B[49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3990\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3991\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3992\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3993\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3994\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3995\u001B[39m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3996\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3997\u001B[39m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3998\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3999\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4000\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4001\u001B[39m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4002\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4003\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001B[39m, in \u001B[36mDataFrameRenderer.to_csv\u001B[39m\u001B[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[39m\n\u001B[32m    993\u001B[39m     created_buffer = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    995\u001B[39m csv_formatter = CSVFormatter(\n\u001B[32m    996\u001B[39m     path_or_buf=path_or_buf,\n\u001B[32m    997\u001B[39m     lineterminator=lineterminator,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1012\u001B[39m     formatter=\u001B[38;5;28mself\u001B[39m.fmt,\n\u001B[32m   1013\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m \u001B[43mcsv_formatter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[32m   1017\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001B[39m, in \u001B[36mCSVFormatter.save\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    247\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    248\u001B[39m \u001B[33;03mCreate the writer & save.\u001B[39;00m\n\u001B[32m    249\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    250\u001B[39m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    256\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    257\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    258\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[32m    259\u001B[39m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[32m    260\u001B[39m     \u001B[38;5;28mself\u001B[39m.writer = csvlib.writer(\n\u001B[32m    261\u001B[39m         handles.handle,\n\u001B[32m    262\u001B[39m         lineterminator=\u001B[38;5;28mself\u001B[39m.lineterminator,\n\u001B[32m   (...)\u001B[39m\u001B[32m    267\u001B[39m         quotechar=\u001B[38;5;28mself\u001B[39m.quotechar,\n\u001B[32m    268\u001B[39m     )\n\u001B[32m    270\u001B[39m     \u001B[38;5;28mself\u001B[39m._save()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\python_pr\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mPermissionError\u001B[39m: [Errno 13] Permission denied: 'C:\\\\Users\\\\wangd\\\\Desktop\\\\yumi.csv'"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T14:54:13.443398600Z",
     "start_time": "2025-12-04T14:52:05.139075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "\n",
    "# è·å–æ‰€æœ‰ç™½é…’è‚¡çš„è‚¡ç¥¨ä»£ç \n",
    "wine_stocks = []\n",
    "\n",
    "try:\n",
    "    # è·å–æ¦‚å¿µæ¿å—æˆåˆ†è‚¡ä¿¡æ¯\n",
    "    concept_list = ak.stock_board_concept_name_ths()\n",
    "    # æŸ¥æ‰¾ç™½é…’ç›¸å…³æ¦‚å¿µ\n",
    "    baijiu_concepts = concept_list[concept_list['name'].str.contains('ç™½é…’|é…’ä¸š|é…¿é…’')]\n",
    "\n",
    "    print(\"æ‰¾åˆ°çš„ç™½é…’ç›¸å…³æ¦‚å¿µæ¿å—ï¼š\")\n",
    "    print(baijiu_concepts[['name', 'code']])\n",
    "\n",
    "    for _, concept in baijiu_concepts.iterrows():\n",
    "        concept_code = concept['code']\n",
    "        # è·å–è¯¥æ¦‚å¿µæ¿å—çš„æˆåˆ†è‚¡\n",
    "        concept_stocks = ak.stock_board_concept_cons_ths(symbol=concept_code)\n",
    "        wine_stocks.extend(concept_stocks['code'].tolist())\n",
    "\n",
    "    # å»é‡\n",
    "    wine_stocks = list(set(wine_stocks))\n",
    "    print(f\"å…±æ‰¾åˆ°{len(wine_stocks)}åªç™½é…’è‚¡\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"é€šè¿‡æ¦‚å¿µæ¿å—è·å–å¤±è´¥: {e}\")\n",
    "    # å¦‚æœæ— æ³•è·å–æ¦‚å¿µæ¿å—ï¼Œä½¿ç”¨ä¸€äº›çŸ¥åçš„ç™½é…’è‚¡ä»£ç ä½œä¸ºå¤‡é€‰\n",
    "    wine_stocks = [\n",
    "        'sh600519',  # è´µå·èŒ…å°\n",
    "        'sz000858',  # äº”ç²®æ¶²\n",
    "        'sz000568',  # æ³¸å·è€çª–\n",
    "        'sh600809',  # å±±è¥¿æ±¾é…’\n",
    "        'sz000860',  # é¡ºé‘«å†œä¸š\n",
    "        'sh600702',  # èˆå¾—é…’ä¸š\n",
    "        'sz000799',  # é…’é¬¼é…’\n",
    "        'sh603369',  # ä»Šä¸–ç¼˜\n",
    "        'sh603589',  # å£å­çª–\n",
    "        'sz002646',  # é’é’ç¨é…’\n",
    "    ]\n",
    "    print(f\"ä½¿ç”¨å¤‡é€‰çš„{len(wine_stocks)}åªç™½é…’è‚¡\")\n",
    "\n",
    "# è·å–æ‰€æœ‰ç™½é…’è‚¡çš„å†å²5åˆ†é’Ÿçº¿æ•°æ®å¹¶åˆå¹¶\n",
    "all_wine_data = pd.DataFrame()\n",
    "\n",
    "# è·å–è‚¡ç¥¨åç§°æ˜ å°„\n",
    "stock_info = ak.stock_info_a_code_name()\n",
    "\n",
    "for stock_code in wine_stocks:\n",
    "    try:\n",
    "        # è·å–å•ä¸ªè‚¡ç¥¨çš„å†å²5åˆ†é’Ÿçº¿æ•°æ®\n",
    "        print(f\"æ­£åœ¨è·å–{stock_code}çš„5åˆ†é’Ÿçº¿æ•°æ®...\")\n",
    "\n",
    "        # è·å–5åˆ†é’Ÿçº¿æ•°æ®\n",
    "        stock_5min_df = ak.stock_zh_a_minute(symbol=stock_code, period=\"5\", adjust=\"\")\n",
    "\n",
    "        if stock_5min_df is not None and not stock_5min_df.empty:\n",
    "            # æ·»åŠ è‚¡ç¥¨ä»£ç å’Œè‚¡ç¥¨åç§°åˆ—ä¾¿äºåŒºåˆ†\n",
    "            stock_name = stock_info[stock_info['code'] == stock_code.replace('sh', '').replace('sz', '')]['name'].values\n",
    "            if len(stock_name) > 0:\n",
    "                stock_name = stock_name[0]\n",
    "            else:\n",
    "                stock_name = \"æœªçŸ¥è‚¡ç¥¨\"\n",
    "\n",
    "            stock_5min_df['stock_code'] = stock_code\n",
    "            stock_5min_df['stock_name'] = stock_name\n",
    "\n",
    "            # åˆå¹¶åˆ°æ€»æ•°æ®æ¡†\n",
    "            all_wine_data = pd.concat([all_wine_data, stock_5min_df], ignore_index=True)\n",
    "\n",
    "            print(f\"å·²è·å–{stock_code}({stock_name})çš„{len(stock_5min_df)}æ¡5åˆ†é’Ÿçº¿æ•°æ®\")\n",
    "        else:\n",
    "            print(f\"{stock_code}æ²¡æœ‰5åˆ†é’Ÿçº¿æ•°æ®æˆ–æ•°æ®ä¸ºç©º\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"è·å–{stock_code}çš„5åˆ†é’Ÿçº¿æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}\")\n",
    "\n",
    "# ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„\n",
    "if not all_wine_data.empty:\n",
    "    save_path = r\"C:\\Users\\wangd\\Desktop\\wine_5min_data.csv\"\n",
    "    all_wine_data.to_csv(save_path, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"æ‰€æœ‰ç™½é…’è‚¡5åˆ†é’Ÿçº¿å†å²è¡Œæƒ…æ•°æ®å·²ä¿å­˜åˆ°{save_path}æ–‡ä»¶ä¸­\")\n",
    "    print(f\"å…±è·å–äº†{len(all_wine_data)}æ¡æ•°æ®è®°å½•\")\n",
    "\n",
    "    if not all_wine_data.empty:\n",
    "        print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {all_wine_data.index.min()} åˆ° {all_wine_data.index.max()}\")\n",
    "\n",
    "    print(\"æ•°æ®é¢„è§ˆï¼š\")\n",
    "    print(all_wine_data.head(10))\n",
    "    print(\"æ•°æ®å°¾éƒ¨é¢„è§ˆï¼š\")\n",
    "    print(all_wine_data.tail(10))\n",
    "else:\n",
    "    print(\"æœªèƒ½è·å–åˆ°ä»»ä½•5åˆ†é’Ÿçº¿æ•°æ®\")\n",
    "    # åˆ›å»ºç©ºæ–‡ä»¶ä½œä¸ºå ä½ç¬¦\n",
    "    empty_df = pd.DataFrame(columns=['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'stock_code', 'stock_name'])\n",
    "    empty_df.to_csv(r\"C:\\Users\\wangd\\Desktop\\wine_5min_data.csv\", encoding=\"utf-8\")\n",
    "    print(f\"å·²åˆ›å»ºç©ºçš„CSVæ–‡ä»¶: C:\\\\Users\\\\wangd\\\\Desktop\\\\wine_5min_data.csv\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "ca70afc038d2077a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79d9619529fd4ccbaeacc30f23651f22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰¾åˆ°çš„ç™½é…’ç›¸å…³æ¦‚å¿µæ¿å—ï¼š\n",
      "   name    code\n",
      "6  ç™½é…’æ¦‚å¿µ  301496\n",
      "é€šè¿‡æ¦‚å¿µæ¿å—è·å–å¤±è´¥: module 'akshare' has no attribute 'stock_board_concept_cons_ths'\n",
      "ä½¿ç”¨å¤‡é€‰çš„10åªç™½é…’è‚¡\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3506b05eed0a437f974f8bdf2412cef4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è·å–sh600519çš„5åˆ†é’Ÿçº¿æ•°æ®...\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
